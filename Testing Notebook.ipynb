{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import mlrose_hiive as mlrose\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Queens Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "problem = mlrose.QueensGenerator().generate(seed=420, size=24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RANDOM HILL CLIMBING TUNING (max attempts, restarts)\n",
    "max_iter = 1000\n",
    "restarts = 100\n",
    "hc_tuning_results = pd.DataFrame(columns=['iter', 'max_attempts', 'restart', 'fitness', 'time'])\n",
    "for i in range(3):\n",
    "    for max_attempts in [1, 5, 10, 25, 50, 75]:\n",
    "        problem.reset()\n",
    "        hc_runner = mlrose.RHCRunner(\n",
    "            problem,\n",
    "            '',\n",
    "            seed=42*(i+1),\n",
    "            iteration_list=[max_iter],\n",
    "            restart_list=[restarts],\n",
    "            max_attempts=max_attempts,\n",
    "            generate_curves=True\n",
    "        )\n",
    "        stats, _ = hc_runner.run()\n",
    "        end_stats = stats.query('Iteration==@max_iter').reset_index(drop=True)\n",
    "        results = pd.DataFrame(index=range(end_stats.shape[0]), columns=hc_tuning_results.columns)\n",
    "        results['iter'] = i + 1\n",
    "        results['max_attempts'] = max_attempts\n",
    "        results['restart'] = end_stats['current_restart'].values\n",
    "        results['fitness'] = end_stats['Fitness'].cummin().values\n",
    "        results['time'] = end_stats['Time'].values\n",
    "        hc_tuning_results = pd.concat([hc_tuning_results, results], axis=0)\n",
    "hc_tuning_results.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hc_tuning_results.groupby(['max_attempts', 'restart'])['time'].mean().unstack().T.plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hc_tuning_results.groupby(['max_attempts', 'restart'])['fitness'].mean().unstack().T.plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hc_tuning_results.to_csv('./results/hc_tuning_queens.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SIMULATED ANNEALING TUNING (max attempts)\n",
    "max_iter = 10000\n",
    "sa_tuning_results_1 = pd.DataFrame(columns=['iter', 'max_attempts', 'init_temp', 'fitness', 'time'])\n",
    "for i in range(5):\n",
    "    for max_attempts in [10, 25, 50, 100, 200, 500]:\n",
    "        problem.reset()\n",
    "        sa_runner = mlrose.SARunner(\n",
    "            problem,\n",
    "            '',\n",
    "            seed=42*(i+1),\n",
    "            iteration_list=[max_iter],\n",
    "            temperature_list=[1],\n",
    "            max_attempts=max_attempts,\n",
    "        )\n",
    "        stats, _ = sa_runner.run()\n",
    "        end_stats = stats.query('Iteration==@max_iter').reset_index(drop=True)\n",
    "        results = pd.DataFrame(index=range(end_stats.shape[0]), columns=sa_tuning_results_1.columns)\n",
    "        results['iter'] = i + 1\n",
    "        results['max_attempts'] = max_attempts\n",
    "        results['init_temp'] = end_stats['schedule_init_temp'].values\n",
    "        results['fitness'] = end_stats['Fitness'].values\n",
    "        results['time'] = end_stats['Time'].values\n",
    "        sa_tuning_results_1 = pd.concat([sa_tuning_results_1, results], axis=0)\n",
    "sa_tuning_results_1.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try to do with matplotlib to get time on right and performance on left\n",
    "sa_tuning_results_1.groupby('max_attempts')['time'].mean().plot();\n",
    "sa_tuning_results_1.groupby('max_attempts')['fitness'].mean().plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sa_tuning_results_1.to_csv('./results/sa_tuning_queens_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SIMULATED ANNEALING TUNING (init temp)\n",
    "max_iter = 10000\n",
    "max_attempts = 200\n",
    "sa_tuning_results_2 = pd.DataFrame(columns=['iter', 'max_attempts', 'init_temp', 'fitness', 'time'])\n",
    "for i in range(5):\n",
    "    for temp in [.1, .5, 1, 2, 5, 10, 50, 100, 1000]:\n",
    "        problem.reset()\n",
    "        sa_runner = mlrose.SARunner(\n",
    "            problem,\n",
    "            '',\n",
    "            seed=42*(i+1),\n",
    "            iteration_list=[max_iter],\n",
    "            temperature_list=[temp],\n",
    "            max_attempts=max_attempts,\n",
    "        )\n",
    "        stats, _ = sa_runner.run()\n",
    "        end_stats = stats.query('Iteration==@max_iter').reset_index(drop=True)\n",
    "        results = pd.DataFrame(index=range(end_stats.shape[0]), columns=sa_tuning_results_2.columns)\n",
    "        results['iter'] = i + 1\n",
    "        results['max_attempts'] = max_attempts\n",
    "        results['init_temp'] = end_stats['schedule_init_temp'].values\n",
    "        results['fitness'] = end_stats['Fitness'].values\n",
    "        results['time'] = end_stats['Time'].values\n",
    "        sa_tuning_results_2 = pd.concat([sa_tuning_results_2, results], axis=0)\n",
    "sa_tuning_results_2.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try to do with matplotlib to get time on right and performance on left\n",
    "sa_tuning_results_2.groupby('init_temp')['time'].mean().plot();\n",
    "sa_tuning_results_2.groupby('init_temp')['fitness'].mean().plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sa_tuning_results_2.to_csv('./results/sa_tuning_queens_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SIMULATED ANNEALING TUNING (decay)\n",
    "max_iter = 10000\n",
    "max_attempts = 200\n",
    "temp = 5\n",
    "sa_tuning_results_3 = pd.DataFrame(columns=['iter', 'max_attempts', 'init_temp', 'decay', 'fitness', 'time'])\n",
    "for i in range(5):\n",
    "    for decay in [.95, .99, .995, .999, .9995, .9999]:\n",
    "        problem.reset()\n",
    "        sa_runner = mlrose.SARunner(\n",
    "            problem,\n",
    "            '',\n",
    "            seed=42*(i+1),\n",
    "            iteration_list=[max_iter],\n",
    "            temperature_list=[mlrose.GeomDecay(temp, decay=decay)],\n",
    "            max_attempts=max_attempts,\n",
    "        )\n",
    "        stats, _ = sa_runner.run()\n",
    "        end_stats = stats.query('Iteration==@max_iter').reset_index(drop=True)\n",
    "        results = pd.DataFrame(index=range(end_stats.shape[0]), columns=sa_tuning_results_3.columns)\n",
    "        results['iter'] = i + 1\n",
    "        results['max_attempts'] = max_attempts\n",
    "        results['init_temp'] = end_stats['schedule_init_temp'].values\n",
    "        results['decay'] = decay\n",
    "        results['fitness'] = end_stats['Fitness'].values\n",
    "        results['time'] = end_stats['Time'].values\n",
    "        sa_tuning_results_3 = pd.concat([sa_tuning_results_3, results], axis=0)\n",
    "sa_tuning_results_3.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try to do with matplotlib to get time on right and performance on left\n",
    "sa_tuning_results_3.groupby('decay')['time'].mean().plot();\n",
    "sa_tuning_results_3.groupby('decay')['fitness'].mean().plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sa_tuning_results_3.groupby('decay')['time'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sa_tuning_results_3.groupby('decay')['fitness'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sa_tuning_results_3.to_csv('./results/sa_tuning_queens_3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(420)\n",
    "problem = mlrose.QueensOpt(length=24, crossover=mlrose.OnePointCrossOver(mlrose.QueensOpt(length=24)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GENETIC ALGORITHM TUNING (mutation rates)\n",
    "max_iter = 1000\n",
    "max_attempts = 200\n",
    "mutation_rates = [.1]\n",
    "population_sizes = [200]\n",
    "cols = ['iter', 'max_attempts', 'pop_size', 'mutation_rate', 'fitness', 'time']\n",
    "ga_tuning_results_3 = pd.DataFrame(columns=cols)\n",
    "for i in range(3):\n",
    "    for mutation_rate in [.01, .1, .2, .5, 1]:\n",
    "        problem.reset()\n",
    "        ga_runner = mlrose.GARunner(\n",
    "            problem,\n",
    "            '',\n",
    "            seed=42*(i+1),\n",
    "            iteration_list=[max_iter],\n",
    "            population_sizes=population_sizes,\n",
    "            mutation_rates=[mutation_rate],\n",
    "            max_attempts=max_attempts\n",
    "        )\n",
    "        stats, _ = ga_runner.run()\n",
    "        end_stats = stats.query('Iteration==@max_iter').reset_index(drop=True)\n",
    "        results = pd.DataFrame(index=range(end_stats.shape[0]), columns=ga_tuning_results_3.columns)\n",
    "        results['iter'] = i + 1\n",
    "        results['max_attempts'] = max_attempts\n",
    "        results['pop_size'] = end_stats['Population Size'].values\n",
    "        results['mutation_rate'] = end_stats['Mutation Rate'].values\n",
    "        results['fitness'] = end_stats['Fitness'].values\n",
    "        results['time'] = end_stats['Time'].values\n",
    "        ga_tuning_results_3 = pd.concat([ga_tuning_results_3, results], axis=0)\n",
    "ga_tuning_results_3.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try to do with matplotlib to get time on right and performance on left\n",
    "ga_tuning_results_3.groupby('mutation_rate')['time'].mean().plot();\n",
    "ga_tuning_results_3.groupby('mutation_rate')['fitness'].mean().plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ga_tuning_results_3.to_csv('./results/ga_tuning_queens_3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GENETIC ALGORITHM TUNING (max attempts)\n",
    "max_iter = 1000\n",
    "population_sizes = [200]\n",
    "mutation_rates = [.5]\n",
    "cols = ['iter', 'max_attempts', 'pop_size', 'mutation_rate', 'fitness', 'time']\n",
    "ga_tuning_results_1 = pd.DataFrame(columns=cols)\n",
    "for i in range(3):\n",
    "    for max_attempts in [10, 25, 50, 100, 200, 500]:\n",
    "        problem.reset()\n",
    "        ga_runner = mlrose.GARunner(\n",
    "            problem,\n",
    "            '',\n",
    "            seed=42*(i+1),\n",
    "            iteration_list=[max_iter],\n",
    "            population_sizes=population_sizes,\n",
    "            mutation_rates=mutation_rates,\n",
    "            max_attempts=max_attempts\n",
    "        )\n",
    "        stats, _ = ga_runner.run()\n",
    "        end_stats = stats.query('Iteration==@max_iter').reset_index(drop=True)\n",
    "        results = pd.DataFrame(index=range(end_stats.shape[0]), columns=ga_tuning_results_1.columns)\n",
    "        results['iter'] = i + 1\n",
    "        results['max_attempts'] = max_attempts\n",
    "        results['pop_size'] = end_stats['Population Size'].values\n",
    "        results['mutation_rate'] = end_stats['Mutation Rate'].values\n",
    "        results['fitness'] = end_stats['Fitness'].values\n",
    "        results['time'] = end_stats['Time'].values\n",
    "        ga_tuning_results_1 = pd.concat([ga_tuning_results_1, results], axis=0)\n",
    "ga_tuning_results_1.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try to do with matplotlib to get time on right and performance on left\n",
    "ga_tuning_results_1.groupby('max_attempts')['time'].mean().plot();\n",
    "ga_tuning_results_1.groupby('max_attempts')['fitness'].mean().plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ga_tuning_results_1.to_csv('./results/ga_tuning_queens_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GENETIC ALGORITHM TUNING (pop size)\n",
    "max_iter = 1000\n",
    "max_attempts = 200\n",
    "mutation_rates = [.5]\n",
    "cols = ['iter', 'max_attempts', 'pop_size', 'mutation_rate', 'fitness', 'time']\n",
    "ga_tuning_results_2 = pd.DataFrame(columns=cols)\n",
    "for i in range(3):\n",
    "    for population_size in [50, 100, 200, 500]:\n",
    "        problem.reset()\n",
    "        ga_runner = mlrose.GARunner(\n",
    "            problem,\n",
    "            '',\n",
    "            seed=42*(i+1),\n",
    "            iteration_list=[max_iter],\n",
    "            population_sizes=[population_size],\n",
    "            mutation_rates=mutation_rates,\n",
    "            max_attempts=max_attempts\n",
    "        )\n",
    "        stats, _ = ga_runner.run()\n",
    "        end_stats = stats.query('Iteration==@max_iter').reset_index(drop=True)\n",
    "        results = pd.DataFrame(index=range(end_stats.shape[0]), columns=ga_tuning_results_2.columns)\n",
    "        results['iter'] = i + 1\n",
    "        results['max_attempts'] = max_attempts\n",
    "        results['pop_size'] = end_stats['Population Size'].values\n",
    "        results['mutation_rate'] = end_stats['Mutation Rate'].values\n",
    "        results['fitness'] = end_stats['Fitness'].values\n",
    "        results['time'] = end_stats['Time'].values\n",
    "        ga_tuning_results_2 = pd.concat([ga_tuning_results_2, results], axis=0)\n",
    "ga_tuning_results_2.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try to do with matplotlib to get time on right and performance on left\n",
    "ga_tuning_results_2.groupby('pop_size')['time'].mean().plot();\n",
    "ga_tuning_results_2.groupby('pop_size')['fitness'].mean().plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ga_tuning_results_2.to_csv('./results/ga_tuning_queens_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GENETIC ALGORITHM TUNING (crossover)\n",
    "max_iter = 1000\n",
    "max_attempts = 200\n",
    "mutation_rates = [.5]\n",
    "population_sizes = [200]\n",
    "cols = ['iter', 'max_attempts', 'pop_size', 'mutation_rate', 'crossover', 'fitness', 'time']\n",
    "ga_tuning_results_4 = pd.DataFrame(columns=cols)\n",
    "crossovers = {\n",
    "    'one_point': mlrose.OnePointCrossOver(mlrose.QueensOpt(length=24)),\n",
    "    'uniform': mlrose.UniformCrossOver(mlrose.QueensOpt(length=24))\n",
    "}\n",
    "for i in range(3):\n",
    "    for c_name, crossover in crossovers.items():\n",
    "        np.random.seed(420)\n",
    "        problem = mlrose.QueensOpt(length=24, crossover=crossover)\n",
    "        problem.reset()\n",
    "        ga_runner = mlrose.GARunner(\n",
    "            problem,\n",
    "            '',\n",
    "            seed=42*(i+1),\n",
    "            iteration_list=[max_iter],\n",
    "            population_sizes=population_sizes,\n",
    "            mutation_rates=[mutation_rate],\n",
    "            max_attempts=max_attempts\n",
    "        )\n",
    "        stats, _ = ga_runner.run()\n",
    "        end_stats = stats.query('Iteration==@max_iter').reset_index(drop=True)\n",
    "        results = pd.DataFrame(index=range(end_stats.shape[0]), columns=ga_tuning_results_4.columns)\n",
    "        results['iter'] = i + 1\n",
    "        results['max_attempts'] = max_attempts\n",
    "        results['crossover'] = c_name\n",
    "        results['pop_size'] = end_stats['Population Size'].values\n",
    "        results['mutation_rate'] = end_stats['Mutation Rate'].values\n",
    "        results['fitness'] = end_stats['Fitness'].values\n",
    "        results['time'] = end_stats['Time'].values\n",
    "        ga_tuning_results_4 = pd.concat([ga_tuning_results_4, results], axis=0)\n",
    "ga_tuning_results_4.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try to do with matplotlib to get time on right and performance on left\n",
    "ga_tuning_results_4.groupby('crossover')['time'].mean().plot();\n",
    "ga_tuning_results_4.groupby('crossover')['fitness'].mean().plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ga_tuning_results_4.to_csv('./results/ga_tuning_queens_4.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "problem = mlrose.QueensGenerator().generate(seed=420, size=24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MIMIC TUNING (max attempts)\n",
    "max_iter = 1000\n",
    "population_sizes = [200]\n",
    "keep_pcts = [.2]\n",
    "cols = ['iter', 'max_attempts', 'pop_size', 'keep_pct', 'fitness', 'time']\n",
    "mimic_tuning_results_1 = pd.DataFrame(columns=cols)\n",
    "for i in range(3):\n",
    "    for max_attempts in [1, 2, 5, 10, 25]:\n",
    "        problem.reset()\n",
    "        mimic_runner = mlrose.MIMICRunner(\n",
    "            problem,\n",
    "            '',\n",
    "            seed=42*(i+1),\n",
    "            iteration_list=[max_iter],\n",
    "            population_sizes=population_sizes,\n",
    "            keep_percent_list=keep_pcts,\n",
    "            max_attempts=max_attempts,\n",
    "            use_fast_mimic=True\n",
    "        )\n",
    "        stats, _ = mimic_runner.run()\n",
    "        end_stats = stats.query('Iteration==@max_iter').reset_index(drop=True)\n",
    "        results = pd.DataFrame(index=range(end_stats.shape[0]), columns=mimic_tuning_results_1.columns)\n",
    "        results['iter'] = i + 1\n",
    "        results['max_attempts'] = max_attempts\n",
    "        results['pop_size'] = end_stats['Population Size'].values\n",
    "        results['keep_pct'] = end_stats['Keep Percent'].values\n",
    "        results['fitness'] = end_stats['Fitness'].values\n",
    "        results['time'] = end_stats['Time'].values\n",
    "        mimic_tuning_results_1 = pd.concat([mimic_tuning_results_1, results], axis=0)\n",
    "mimic_tuning_results_1.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try to do with matplotlib to get time on right and performance on left\n",
    "mimic_tuning_results_1.groupby('max_attempts')['time'].mean().plot();\n",
    "mimic_tuning_results_1.groupby('max_attempts')['fitness'].mean().plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mimic_tuning_results_1.to_csv('./results/mimic_tuning_queens_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MIMIC TUNING (pop size)\n",
    "max_iter = 1000\n",
    "keep_pcts = [.2]\n",
    "max_attempts = 2\n",
    "cols = ['iter', 'max_attempts', 'pop_size', 'keep_pct', 'fitness', 'time']\n",
    "mimic_tuning_results_2 = pd.DataFrame(columns=cols)\n",
    "for i in range(3):\n",
    "    for pop_size in [50, 100, 200, 500, 1000, 2000]:\n",
    "        population_sizes = [pop_size]\n",
    "        problem.reset()\n",
    "        mimic_runner = mlrose.MIMICRunner(\n",
    "            problem,\n",
    "            '',\n",
    "            seed=42*(i+1),\n",
    "            iteration_list=[max_iter],\n",
    "            population_sizes=population_sizes,\n",
    "            keep_percent_list=keep_pcts,\n",
    "            max_attempts=max_attempts,\n",
    "            use_fast_mimic=True\n",
    "        )\n",
    "        stats, _ = mimic_runner.run()\n",
    "        end_stats = stats.query('Iteration==@max_iter').reset_index(drop=True)\n",
    "        results = pd.DataFrame(index=range(end_stats.shape[0]), columns=mimic_tuning_results_2.columns)\n",
    "        results['iter'] = i + 1\n",
    "        results['max_attempts'] = max_attempts\n",
    "        results['pop_size'] = end_stats['Population Size'].values\n",
    "        results['keep_pct'] = end_stats['Keep Percent'].values\n",
    "        results['fitness'] = end_stats['Fitness'].values\n",
    "        results['time'] = end_stats['Time'].values\n",
    "        mimic_tuning_results_2 = pd.concat([mimic_tuning_results_2, results], axis=0)\n",
    "mimic_tuning_results_2.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try to do with matplotlib to get time on right and performance on left\n",
    "mimic_tuning_results_2.groupby('pop_size')['time'].mean().plot();\n",
    "mimic_tuning_results_2.groupby('pop_size')['fitness'].mean().plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mimic_tuning_results_2.to_csv('./results/mimic_tuning_queens_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MIMIC TUNING (keep pct)\n",
    "max_iter = 1000\n",
    "population_sizes = [1000]\n",
    "max_attempts = 2\n",
    "cols = ['iter', 'max_attempts', 'pop_size', 'keep_pct', 'fitness', 'time']\n",
    "mimic_tuning_results_3 = pd.DataFrame(columns=cols)\n",
    "for i in range(3):\n",
    "    for keep_pct in [.05, .1, .2, .3, .5]:\n",
    "        keep_pcts = [keep_pct]\n",
    "        problem.reset()\n",
    "        mimic_runner = mlrose.MIMICRunner(\n",
    "            problem,\n",
    "            '',\n",
    "            seed=42*(i+1),\n",
    "            iteration_list=[max_iter],\n",
    "            population_sizes=population_sizes,\n",
    "            keep_percent_list=keep_pcts,\n",
    "            max_attempts=max_attempts,\n",
    "            use_fast_mimic=True\n",
    "        )\n",
    "        stats, _ = mimic_runner.run()\n",
    "        end_stats = stats.query('Iteration==@max_iter').reset_index(drop=True)\n",
    "        results = pd.DataFrame(index=range(end_stats.shape[0]), columns=mimic_tuning_results_3.columns)\n",
    "        results['iter'] = i + 1\n",
    "        results['max_attempts'] = max_attempts\n",
    "        results['pop_size'] = end_stats['Population Size'].values\n",
    "        results['keep_pct'] = end_stats['Keep Percent'].values\n",
    "        results['fitness'] = end_stats['Fitness'].values\n",
    "        results['time'] = end_stats['Time'].values\n",
    "        mimic_tuning_results_3 = pd.concat([mimic_tuning_results_3, results], axis=0)\n",
    "mimic_tuning_results_3.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mimic_tuning_results_3.groupby('keep_pct')['time'].mean().plot();\n",
    "mimic_tuning_results_3.groupby('keep_pct')['fitness'].mean().plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mimic_tuning_results_3.to_csv('./results/mimic_tuning_queens_3.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Queens Final Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "problem_sizes = [16, 24, 32]\n",
    "prob_seed = 4200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RANDOM HILL CLIMBING\n",
    "max_iter = 1000\n",
    "step = 10\n",
    "iteration_list = np.arange(step, max_iter+1, step)\n",
    "max_attempts = 75\n",
    "restarts = 10\n",
    "cols = ['prob_size', 'iter', 'iteration', 'max_attempts', 'restarts', 'fitness', 'time', 'f_evals']\n",
    "hc_final_results = pd.DataFrame(columns=cols)\n",
    "for prob_size in problem_sizes:\n",
    "    for i in range(3):\n",
    "        problem = mlrose.QueensGenerator().generate(seed=prob_seed, size=prob_size)\n",
    "        hc_runner = mlrose.RHCRunner(\n",
    "            problem,\n",
    "            '',\n",
    "            seed=420*(i+1),\n",
    "            iteration_list=iteration_list,\n",
    "            restart_list=[restarts],\n",
    "            max_attempts=max_attempts,\n",
    "            generate_curves=True\n",
    "        )\n",
    "        stats, _ = hc_runner.run()\n",
    "        n_rows = stats.drop_duplicates('Iteration').shape[0]\n",
    "        results = pd.DataFrame(index=range(n_rows), columns=hc_final_results.columns)\n",
    "        results['prob_size'] = prob_size\n",
    "        results['iter'] = i + 1\n",
    "        results['max_attempts'] = max_attempts\n",
    "        results['restarts'] = restarts\n",
    "        results['iteration'] = stats.drop_duplicates('Iteration')['Iteration'].values\n",
    "        results['fitness'] = stats.groupby('Iteration')['Fitness'].min().values\n",
    "        stats['time_per_iter'] = stats['Time'].diff().fillna(stats['Time'].min())\n",
    "        results['time'] = stats.groupby('Iteration')['time_per_iter'].mean().cumsum().values\n",
    "        stats['evals_per_iter'] = stats['FEvals'].diff().fillna(stats['FEvals'].min())\n",
    "        results['f_evals'] = stats.groupby('Iteration')['evals_per_iter'].mean().cumsum().values\n",
    "        hc_final_results = pd.concat([hc_final_results, results], axis=0)\n",
    "hc_final_results.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for prob_size in problem_sizes:\n",
    "    hc_final_results.query(\n",
    "        'prob_size==@prob_size'\n",
    "    ).drop_duplicates(['time']).groupby('iteration')['fitness'].mean().plot(\n",
    "        label=prob_size, legend=True\n",
    "    );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hc_final_results.to_csv('./results/hc_final_queens.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SIMULATED ANNEALING\n",
    "max_iter = 10000\n",
    "step = 10\n",
    "iteration_list = np.arange(step, max_iter+1, step)\n",
    "max_attempts = 200\n",
    "decay = .995\n",
    "init_temp = 5\n",
    "cols = ['prob_size', 'iter', 'iteration', 'max_attempts', 'init_temp', 'decay', 'fitness', 'time', 'f_evals']\n",
    "sa_final_results = pd.DataFrame(columns=cols)\n",
    "for prob_size in problem_sizes:\n",
    "    for i in range(3):\n",
    "        problem = mlrose.QueensGenerator().generate(seed=prob_seed, size=prob_size)\n",
    "        sa_runner = mlrose.SARunner(\n",
    "            problem,\n",
    "            '',\n",
    "            seed=420*(i+1),\n",
    "            iteration_list=iteration_list,\n",
    "            max_attempts=max_attempts,\n",
    "            temperature_list=[mlrose.GeomDecay(init_temp, decay=decay)],\n",
    "        )\n",
    "        stats, _ = sa_runner.run()\n",
    "        n_rows = stats.shape[0]\n",
    "        results = pd.DataFrame(index=range(n_rows), columns=sa_final_results.columns)\n",
    "        results['prob_size'] = prob_size\n",
    "        results['iter'] = i + 1\n",
    "        results['max_attempts'] = max_attempts\n",
    "        results['init_temp'] = init_temp\n",
    "        results['decay'] = decay\n",
    "        results['iteration'] = stats['Iteration'].values\n",
    "        results['fitness'] = stats['Fitness'].values\n",
    "        results['time'] = stats['Time'].values\n",
    "        results['f_evals'] = stats['FEvals'].values\n",
    "        sa_final_results = pd.concat([sa_final_results, results], axis=0)\n",
    "sa_final_results.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for prob_size in problem_sizes:\n",
    "    sa_final_results.query(\n",
    "        'prob_size==@prob_size'\n",
    "    ).drop_duplicates(['time']).groupby('iteration')['fitness'].mean().plot(\n",
    "        label=prob_size, legend=True\n",
    "    );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sa_final_results.to_csv('./results/sa_final_queens.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GENETIC ALGORITHM\n",
    "max_iter = 1000\n",
    "step = 10\n",
    "iteration_list = np.arange(step, max_iter+1, step)\n",
    "max_attempts = 200\n",
    "pop_size = 200\n",
    "mutation_rate = 1\n",
    "cols = ['prob_size', 'iter', 'iteration', 'max_attempts', 'pop_size', 'mutation_rate', 'fitness', 'time', 'f_evals']\n",
    "ga_final_results = pd.DataFrame(columns=cols)\n",
    "for prob_size in problem_sizes:\n",
    "    for i in range(3):\n",
    "        problem = mlrose.QueensGenerator().generate(seed=prob_seed, size=prob_size)\n",
    "        ga_runner = mlrose.GARunner(\n",
    "            problem,\n",
    "            '',\n",
    "            seed=420*(i+1),\n",
    "            iteration_list=iteration_list,\n",
    "            max_attempts=max_attempts,\n",
    "            population_sizes=[pop_size],\n",
    "            mutation_rates=[mutation_rate]\n",
    "        )\n",
    "        stats, _ = ga_runner.run()\n",
    "        n_rows = stats.shape[0]\n",
    "        results = pd.DataFrame(index=range(n_rows), columns=ga_final_results.columns)\n",
    "        results['prob_size'] = prob_size\n",
    "        results['iter'] = i + 1\n",
    "        results['max_attempts'] = max_attempts\n",
    "        results['pop_size'] = pop_size\n",
    "        results['mutation_rate'] = mutation_rate\n",
    "        results['iteration'] = stats['Iteration'].values\n",
    "        results['fitness'] = stats['Fitness'].values\n",
    "        results['time'] = stats['Time'].values\n",
    "        results['f_evals'] = stats['FEvals'].values\n",
    "        ga_final_results = pd.concat([ga_final_results, results], axis=0)\n",
    "ga_final_results.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for prob_size in problem_sizes:\n",
    "    ga_final_results.query(\n",
    "        'prob_size==@prob_size'\n",
    "    ).drop_duplicates(['time']).groupby('iteration')['fitness'].mean().plot(\n",
    "        label=prob_size, legend=True\n",
    "    );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ga_final_results.to_csv('./results/ga_final_queens.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MIMIC\n",
    "max_iter = 1000\n",
    "step = 10\n",
    "iteration_list = np.arange(step, max_iter+1, step)\n",
    "max_attempts = 2\n",
    "pop_size = 1000\n",
    "keep_pct = .1\n",
    "cols = ['prob_size', 'iter', 'iteration', 'max_attempts', 'pop_size', 'keep_pct', 'fitness', 'time', 'f_evals']\n",
    "mimic_final_results = pd.DataFrame(columns=cols)\n",
    "for prob_size in problem_sizes:\n",
    "    for i in range(3):\n",
    "        problem = mlrose.QueensGenerator().generate(seed=prob_seed, size=prob_size)\n",
    "        mimic_runner = mlrose.MIMICRunner(\n",
    "            problem,\n",
    "            '',\n",
    "            seed=420*(i+1),\n",
    "            iteration_list=iteration_list,\n",
    "            max_attempts=max_attempts,\n",
    "            population_sizes=[pop_size],\n",
    "            keep_percent_list=[keep_pct],\n",
    "            use_fast_mimic=True\n",
    "        )\n",
    "        stats, _ = mimic_runner.run()\n",
    "        n_rows = stats.shape[0]\n",
    "        results = pd.DataFrame(index=range(n_rows), columns=mimic_final_results.columns)\n",
    "        results['prob_size'] = prob_size\n",
    "        results['iter'] = i + 1\n",
    "        results['max_attempts'] = max_attempts\n",
    "        results['pop_size'] = pop_size\n",
    "        results['keep_pct'] = keep_pct\n",
    "        results['iteration'] = stats['Iteration'].values\n",
    "        results['fitness'] = stats['Fitness'].values\n",
    "        results['time'] = stats['Time'].values\n",
    "        results['f_evals'] = stats['FEvals'].values\n",
    "        mimic_final_results = pd.concat([mimic_final_results, results], axis=0)\n",
    "mimic_final_results.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for prob_size in problem_sizes:\n",
    "    mimic_final_results.query(\n",
    "        'prob_size==@prob_size'\n",
    "    ).drop_duplicates(['time']).groupby('iteration')['fitness'].mean().plot(\n",
    "        label=prob_size, legend=True\n",
    "    );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mimic_final_results.to_csv('./results/mimic_final_queens.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Knapsack Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "problem = mlrose.KnapsackGenerator().generate(\n",
    "    seed=420, max_item_count=2, max_weight_pct=.35, number_of_items_types=110\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HILL CLIMBING TUNING (restarts and max attempts)\n",
    "max_iter = 1000\n",
    "restarts = 100\n",
    "hc_tuning_results = pd.DataFrame(columns=['iter', 'max_attempts', 'restart', 'fitness', 'time'])\n",
    "for max_attempts in [1, 5, 10, 25, 50]:\n",
    "    for i in range(5):\n",
    "        problem.reset()\n",
    "        hc_runner = mlrose.RHCRunner(\n",
    "            problem,\n",
    "            '',\n",
    "            seed=42*(i+1),\n",
    "            iteration_list=[max_iter],\n",
    "            restart_list=[restarts],\n",
    "            max_attempts=max_attempts,\n",
    "            generate_curves=True\n",
    "        )\n",
    "        stats, _ = hc_runner.run()\n",
    "        end_stats = stats.query('Iteration==@max_iter').reset_index(drop=True)\n",
    "        results = pd.DataFrame(index=range(end_stats.shape[0]), columns=hc_tuning_results.columns)\n",
    "        results['iter'] = i + 1\n",
    "        results['max_attempts'] = max_attempts\n",
    "        results['restart'] = end_stats['current_restart'].values\n",
    "        results['fitness'] = end_stats['Fitness'].cummax().values\n",
    "        results['time'] = end_stats['Time'].values\n",
    "        hc_tuning_results = pd.concat([hc_tuning_results, results], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hc_tuning_results.groupby(['max_attempts', 'restart'])['time'].mean().unstack().T.plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hc_tuning_results.groupby(['max_attempts', 'restart'])['fitness'].mean().unstack().T.plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hc_tuning_results.to_csv('./results/hc_tuning_ks.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SIMULATED ANNEALING TUNING (max attempts)\n",
    "max_iter = 100000\n",
    "sa_tuning_results_1 = pd.DataFrame(columns=['iter', 'max_attempts', 'init_temp', 'fitness', 'time'])\n",
    "for i in range(5):\n",
    "    for max_attempts in [10, 25, 50, 100, 200, 500]:\n",
    "        problem.reset()\n",
    "        sa_runner = mlrose.SARunner(\n",
    "            problem,\n",
    "            '',\n",
    "            seed=42*(i+1),\n",
    "            iteration_list=[max_iter],\n",
    "            temperature_list=[1],\n",
    "            max_attempts=max_attempts,\n",
    "        )\n",
    "        stats, _ = sa_runner.run()\n",
    "        end_stats = stats.query('Iteration==@max_iter').reset_index(drop=True)\n",
    "        results = pd.DataFrame(index=range(end_stats.shape[0]), columns=sa_tuning_results_1.columns)\n",
    "        results['iter'] = i + 1\n",
    "        results['max_attempts'] = max_attempts\n",
    "        results['init_temp'] = end_stats['schedule_init_temp'].values\n",
    "        results['fitness'] = end_stats['Fitness'].values\n",
    "        results['time'] = end_stats['Time'].values\n",
    "        sa_tuning_results_1 = pd.concat([sa_tuning_results_1, results], axis=0)\n",
    "sa_tuning_results_1.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sa_tuning_results_1.groupby('max_attempts')['time'].mean().plot();\n",
    "sa_tuning_results_1.groupby('max_attempts')['fitness'].mean().plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sa_tuning_results_1.to_csv('./results/sa_tuning_ks_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SIMULATED ANNEALING TUNING (init temp)\n",
    "max_iter = 100000\n",
    "max_attempts = 500\n",
    "sa_tuning_results_2 = pd.DataFrame(columns=['iter', 'max_attempts', 'init_temp', 'fitness', 'time'])\n",
    "for i in range(5):\n",
    "    for temp in [.1, .5, 1, 2, 5, 10, 50, 100, 1000]:\n",
    "        problem.reset()\n",
    "        sa_runner = mlrose.SARunner(\n",
    "            problem,\n",
    "            '',\n",
    "            seed=42*(i+1),\n",
    "            iteration_list=[max_iter],\n",
    "            temperature_list=[temp],\n",
    "            max_attempts=max_attempts,\n",
    "        )\n",
    "        stats, _ = sa_runner.run()\n",
    "        end_stats = stats.query('Iteration==@max_iter').reset_index(drop=True)\n",
    "        results = pd.DataFrame(index=range(end_stats.shape[0]), columns=sa_tuning_results_2.columns)\n",
    "        results['iter'] = i + 1\n",
    "        results['max_attempts'] = max_attempts\n",
    "        results['init_temp'] = end_stats['schedule_init_temp'].values\n",
    "        results['fitness'] = end_stats['Fitness'].values\n",
    "        results['time'] = end_stats['Time'].values\n",
    "        sa_tuning_results_2 = pd.concat([sa_tuning_results_2, results], axis=0)\n",
    "sa_tuning_results_2.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sa_tuning_results_2.groupby('init_temp')['time'].mean().plot();\n",
    "sa_tuning_results_2.groupby('init_temp')['fitness'].mean().plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sa_tuning_results_2.to_csv('./results/sa_tuning_ks_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SIMULATED ANNEALING TUNING (decay)\n",
    "max_iter = 100000\n",
    "max_attempts = 500\n",
    "temp = 50\n",
    "sa_tuning_results_3 = pd.DataFrame(columns=['iter', 'max_attempts', 'init_temp', 'decay', 'fitness', 'time'])\n",
    "for i in range(5):\n",
    "    for decay in [.95, .99, .995, .999, .9995, .9999]:\n",
    "        problem.reset()\n",
    "        sa_runner = mlrose.SARunner(\n",
    "            problem,\n",
    "            '',\n",
    "            seed=42*(i+1),\n",
    "            iteration_list=[max_iter],\n",
    "            temperature_list=[mlrose.GeomDecay(temp, decay=decay)],\n",
    "            max_attempts=max_attempts,\n",
    "        )\n",
    "        stats, _ = sa_runner.run()\n",
    "        end_stats = stats.query('Iteration==@max_iter').reset_index(drop=True)\n",
    "        results = pd.DataFrame(index=range(end_stats.shape[0]), columns=sa_tuning_results_3.columns)\n",
    "        results['iter'] = i + 1\n",
    "        results['max_attempts'] = max_attempts\n",
    "        results['init_temp'] = end_stats['schedule_init_temp'].values\n",
    "        results['decay'] = decay\n",
    "        results['fitness'] = end_stats['Fitness'].values\n",
    "        results['time'] = end_stats['Time'].values\n",
    "        sa_tuning_results_3 = pd.concat([sa_tuning_results_3, results], axis=0)\n",
    "sa_tuning_results_3.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sa_tuning_results_3.groupby('decay')['time'].mean().plot();\n",
    "sa_tuning_results_3.groupby('decay')['fitness'].mean().plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sa_tuning_results_3.groupby('decay')['time'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sa_tuning_results_3.groupby('decay')['fitness'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sa_tuning_results_3.to_csv('./results/sa_tuning_ks_3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GENETIC ALGORITHM TUNING (mutation rates)\n",
    "max_iter = 1000\n",
    "max_attempts = 200\n",
    "population_sizes = [200]\n",
    "cols = ['iter', 'max_attempts', 'pop_size', 'mutation_rate', 'fitness', 'time']\n",
    "ga_tuning_results_1 = pd.DataFrame(columns=cols)\n",
    "for i in range(3):\n",
    "    for mutation_rate in [.01, .1, .2, .5, 1]:\n",
    "        problem.reset()\n",
    "        ga_runner = mlrose.GARunner(\n",
    "            problem,\n",
    "            '',\n",
    "            seed=42*(i+1),\n",
    "            iteration_list=[max_iter],\n",
    "            population_sizes=population_sizes,\n",
    "            mutation_rates=[mutation_rate],\n",
    "            max_attempts=max_attempts\n",
    "        )\n",
    "        stats, _ = ga_runner.run()\n",
    "        end_stats = stats.query('Iteration==@max_iter').reset_index(drop=True)\n",
    "        results = pd.DataFrame(index=range(end_stats.shape[0]), columns=ga_tuning_results_1.columns)\n",
    "        results['iter'] = i + 1\n",
    "        results['max_attempts'] = max_attempts\n",
    "        results['pop_size'] = end_stats['Population Size'].values\n",
    "        results['mutation_rate'] = end_stats['Mutation Rate'].values\n",
    "        results['fitness'] = end_stats['Fitness'].values\n",
    "        results['time'] = end_stats['Time'].values\n",
    "        ga_tuning_results_1 = pd.concat([ga_tuning_results_1, results], axis=0)\n",
    "ga_tuning_results_1.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ga_tuning_results_1.groupby('mutation_rate')['time'].mean().plot();\n",
    "ga_tuning_results_1.groupby('mutation_rate')['fitness'].mean().plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ga_tuning_results_1.to_csv('./results/ga_tuning_ks_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GENETIC ALGORITHM TUNING (max attempts)\n",
    "max_iter = 1000\n",
    "population_sizes = [200]\n",
    "mutation_rates = [.1]\n",
    "cols = ['iter', 'max_attempts', 'pop_size', 'mutation_rate', 'fitness', 'time']\n",
    "ga_tuning_results_2 = pd.DataFrame(columns=cols)\n",
    "for i in range(3):\n",
    "    for max_attempts in [10, 25, 50, 100, 200, 500]:\n",
    "        problem.reset()\n",
    "        ga_runner = mlrose.GARunner(\n",
    "            problem,\n",
    "            '',\n",
    "            seed=42*(i+1),\n",
    "            iteration_list=[max_iter],\n",
    "            population_sizes=population_sizes,\n",
    "            mutation_rates=mutation_rates,\n",
    "            max_attempts=max_attempts\n",
    "        )\n",
    "        stats, _ = ga_runner.run()\n",
    "        end_stats = stats.query('Iteration==@max_iter').reset_index(drop=True)\n",
    "        results = pd.DataFrame(index=range(end_stats.shape[0]), columns=ga_tuning_results_2.columns)\n",
    "        results['iter'] = i + 1\n",
    "        results['max_attempts'] = max_attempts\n",
    "        results['pop_size'] = end_stats['Population Size'].values\n",
    "        results['mutation_rate'] = end_stats['Mutation Rate'].values\n",
    "        results['fitness'] = end_stats['Fitness'].values\n",
    "        results['time'] = end_stats['Time'].values\n",
    "        ga_tuning_results_2 = pd.concat([ga_tuning_results_2, results], axis=0)\n",
    "ga_tuning_results_2.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ga_tuning_results_2.groupby('max_attempts')['time'].mean().plot();\n",
    "ga_tuning_results_2.groupby('max_attempts')['fitness'].mean().plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ga_tuning_results_2.to_csv('./results/ga_tuning_ks_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GENETIC ALGORITHM TUNING (pop size)\n",
    "max_iter = 1000\n",
    "max_attempts = 25\n",
    "mutation_rates = [.1]\n",
    "cols = ['iter', 'max_attempts', 'pop_size', 'mutation_rate', 'fitness', 'time']\n",
    "ga_tuning_results_3 = pd.DataFrame(columns=cols)\n",
    "for i in range(3):\n",
    "    for population_size in [50, 100, 200, 500]:\n",
    "        problem.reset()\n",
    "        ga_runner = mlrose.GARunner(\n",
    "            problem,\n",
    "            '',\n",
    "            seed=42*(i+1),\n",
    "            iteration_list=[max_iter],\n",
    "            population_sizes=[population_size],\n",
    "            mutation_rates=mutation_rates,\n",
    "            max_attempts=max_attempts\n",
    "        )\n",
    "        stats, _ = ga_runner.run()\n",
    "        end_stats = stats.query('Iteration==@max_iter').reset_index(drop=True)\n",
    "        results = pd.DataFrame(index=range(end_stats.shape[0]), columns=ga_tuning_results_3.columns)\n",
    "        results['iter'] = i + 1\n",
    "        results['max_attempts'] = max_attempts\n",
    "        results['pop_size'] = end_stats['Population Size'].values\n",
    "        results['mutation_rate'] = end_stats['Mutation Rate'].values\n",
    "        results['fitness'] = end_stats['Fitness'].values\n",
    "        results['time'] = end_stats['Time'].values\n",
    "        ga_tuning_results_3 = pd.concat([ga_tuning_results_3, results], axis=0)\n",
    "ga_tuning_results_3.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ga_tuning_results_3.groupby('pop_size')['time'].mean().plot();\n",
    "ga_tuning_results_3.groupby('pop_size')['fitness'].mean().plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ga_tuning_results_3.groupby('pop_size')['fitness'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ga_tuning_results_3.groupby('pop_size')['time'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ga_tuning_results_3.to_csv('./results/ga_tuning_ks_3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MIMIC TUNING (max attempts)\n",
    "max_iter = 1000\n",
    "population_sizes = [200]\n",
    "keep_pcts = [.2]\n",
    "cols = ['iter', 'max_attempts', 'pop_size', 'keep_pct', 'fitness', 'time']\n",
    "mimic_tuning_results_1 = pd.DataFrame(columns=cols)\n",
    "for i in range(3):\n",
    "    for max_attempts in [1, 2, 5, 10, 25]:\n",
    "        problem.reset()\n",
    "        mimic_runner = mlrose.MIMICRunner(\n",
    "            problem,\n",
    "            '',\n",
    "            seed=42*(i+1),\n",
    "            iteration_list=[max_iter],\n",
    "            population_sizes=population_sizes,\n",
    "            keep_percent_list=keep_pcts,\n",
    "            max_attempts=max_attempts,\n",
    "            use_fast_mimic=True\n",
    "        )\n",
    "        stats, _ = mimic_runner.run()\n",
    "        end_stats = stats.query('Iteration==@max_iter').reset_index(drop=True)\n",
    "        results = pd.DataFrame(index=range(end_stats.shape[0]), columns=mimic_tuning_results_1.columns)\n",
    "        results['iter'] = i + 1\n",
    "        results['max_attempts'] = max_attempts\n",
    "        results['pop_size'] = end_stats['Population Size'].values\n",
    "        results['keep_pct'] = end_stats['Keep Percent'].values\n",
    "        results['fitness'] = end_stats['Fitness'].values\n",
    "        results['time'] = end_stats['Time'].values\n",
    "        mimic_tuning_results_1 = pd.concat([mimic_tuning_results_1, results], axis=0)\n",
    "mimic_tuning_results_1.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mimic_tuning_results_1.groupby('max_attempts')['time'].mean().plot();\n",
    "mimic_tuning_results_1.groupby('max_attempts')['fitness'].mean().plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mimic_tuning_results_1.groupby('max_attempts')['fitness'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mimic_tuning_results_1.to_csv('./results/mimic_tuning_ks_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MIMIC TUNING (pop size)\n",
    "max_iter = 1000\n",
    "keep_pcts = [.2]\n",
    "max_attempts = 5\n",
    "cols = ['iter', 'max_attempts', 'pop_size', 'keep_pct', 'fitness', 'time']\n",
    "mimic_tuning_results_2 = pd.DataFrame(columns=cols)\n",
    "for i in range(3):\n",
    "    for pop_size in [50, 100, 200, 500, 1000, 2000]:\n",
    "        population_sizes = [pop_size]\n",
    "        problem.reset()\n",
    "        mimic_runner = mlrose.MIMICRunner(\n",
    "            problem,\n",
    "            '',\n",
    "            seed=42*(i+1),\n",
    "            iteration_list=[max_iter],\n",
    "            population_sizes=population_sizes,\n",
    "            keep_percent_list=keep_pcts,\n",
    "            max_attempts=max_attempts,\n",
    "            use_fast_mimic=True\n",
    "        )\n",
    "        stats, _ = mimic_runner.run()\n",
    "        end_stats = stats.query('Iteration==@max_iter').reset_index(drop=True)\n",
    "        results = pd.DataFrame(index=range(end_stats.shape[0]), columns=mimic_tuning_results_2.columns)\n",
    "        results['iter'] = i + 1\n",
    "        results['max_attempts'] = max_attempts\n",
    "        results['pop_size'] = end_stats['Population Size'].values\n",
    "        results['keep_pct'] = end_stats['Keep Percent'].values\n",
    "        results['fitness'] = end_stats['Fitness'].values\n",
    "        results['time'] = end_stats['Time'].values\n",
    "        mimic_tuning_results_2 = pd.concat([mimic_tuning_results_2, results], axis=0)\n",
    "mimic_tuning_results_2.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mimic_tuning_results_2.groupby('pop_size')['time'].mean().plot();\n",
    "mimic_tuning_results_2.groupby('pop_size')['fitness'].mean().plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mimic_tuning_results_2.groupby('pop_size')['time'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mimic_tuning_results_2.to_csv('./results/mimic_tuning_ks_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MIMIC TUNING (keep pct)\n",
    "max_iter = 1000\n",
    "population_sizes = [1000]\n",
    "max_attempts = 5\n",
    "cols = ['iter', 'max_attempts', 'pop_size', 'keep_pct', 'fitness', 'time']\n",
    "mimic_tuning_results_3 = pd.DataFrame(columns=cols)\n",
    "for i in range(3):\n",
    "    for keep_pct in [.05, .1, .2, .3, .5]:\n",
    "        keep_pcts = [keep_pct]\n",
    "        problem.reset()\n",
    "        mimic_runner = mlrose.MIMICRunner(\n",
    "            problem,\n",
    "            '',\n",
    "            seed=42*(i+1),\n",
    "            iteration_list=[max_iter],\n",
    "            population_sizes=population_sizes,\n",
    "            keep_percent_list=keep_pcts,\n",
    "            max_attempts=max_attempts,\n",
    "            use_fast_mimic=True\n",
    "        )\n",
    "        stats, _ = mimic_runner.run()\n",
    "        end_stats = stats.query('Iteration==@max_iter').reset_index(drop=True)\n",
    "        results = pd.DataFrame(index=range(end_stats.shape[0]), columns=mimic_tuning_results_3.columns)\n",
    "        results['iter'] = i + 1\n",
    "        results['max_attempts'] = max_attempts\n",
    "        results['pop_size'] = end_stats['Population Size'].values\n",
    "        results['keep_pct'] = end_stats['Keep Percent'].values\n",
    "        results['fitness'] = end_stats['Fitness'].values\n",
    "        results['time'] = end_stats['Time'].values\n",
    "        mimic_tuning_results_3 = pd.concat([mimic_tuning_results_3, results], axis=0)\n",
    "mimic_tuning_results_3.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mimic_tuning_results_3.groupby('keep_pct')['time'].mean().plot();\n",
    "mimic_tuning_results_3.groupby('keep_pct')['fitness'].mean().plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mimic_tuning_results_3.groupby('keep_pct')['fitness'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mimic_tuning_results_3.groupby('keep_pct')['time'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mimic_tuning_results_3.to_csv('./results/mimic_tuning_ks_3.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Knapsack Final Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SKIP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4 Peaks Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_size = 110\n",
    "fitness_fn = mlrose.FourPeaks(t_pct=.1)\n",
    "basic_opt = mlrose.DiscreteOpt(prob_size, fitness_fn=fitness_fn)\n",
    "crossover = mlrose.OnePointCrossOver(basic_opt)\n",
    "mutator = mlrose.ChangeOneMutator(basic_opt)\n",
    "np.random.seed(420)\n",
    "problem = mlrose.DiscreteOpt(prob_size, fitness_fn=fitness_fn, crossover=crossover, mutator=mutator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HILL CLIMBING TUNING (restarts and max attempts)\n",
    "max_iter = 1000\n",
    "restarts = 100\n",
    "hc_tuning_results = pd.DataFrame(columns=['iter', 'max_attempts', 'restart', 'fitness', 'time'])\n",
    "for max_attempts in [1, 5, 10, 25, 50, 100]:\n",
    "    for i in range(5):\n",
    "        problem.reset()\n",
    "        hc_runner = mlrose.RHCRunner(\n",
    "            problem,\n",
    "            '',\n",
    "            seed=42*(i+1),\n",
    "            iteration_list=[max_iter],\n",
    "            restart_list=[restarts],\n",
    "            max_attempts=max_attempts,\n",
    "            generate_curves=True\n",
    "        )\n",
    "        stats, _ = hc_runner.run()\n",
    "        end_stats = stats.query('Iteration==@max_iter').reset_index(drop=True)\n",
    "        results = pd.DataFrame(index=range(end_stats.shape[0]), columns=hc_tuning_results.columns)\n",
    "        results['iter'] = i + 1\n",
    "        results['max_attempts'] = max_attempts\n",
    "        results['restart'] = end_stats['current_restart'].values\n",
    "        results['fitness'] = end_stats['Fitness'].cummax().values\n",
    "        results['time'] = end_stats['Time'].values\n",
    "        hc_tuning_results = pd.concat([hc_tuning_results, results], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hc_tuning_results.groupby(['max_attempts', 'restart'])['time'].mean().unstack().T.plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hc_tuning_results.groupby(['max_attempts', 'restart'])['fitness'].mean().unstack().T.plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hc_tuning_results.to_csv('./results/hc_tuning_4pks.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SIMULATED ANNEALING TUNING (max attempts)\n",
    "max_iter = 10000\n",
    "sa_tuning_results_1 = pd.DataFrame(columns=['iter', 'max_attempts', 'init_temp', 'fitness', 'time'])\n",
    "for i in range(5):\n",
    "    for max_attempts in [10, 25, 50, 100, 200, 500]:\n",
    "        problem.reset()\n",
    "        sa_runner = mlrose.SARunner(\n",
    "            problem,\n",
    "            '',\n",
    "            seed=42*(i+1),\n",
    "            iteration_list=[max_iter],\n",
    "            temperature_list=[1],\n",
    "            max_attempts=max_attempts,\n",
    "        )\n",
    "        stats, _ = sa_runner.run()\n",
    "        end_stats = stats.query('Iteration==@max_iter').reset_index(drop=True)\n",
    "        results = pd.DataFrame(index=range(end_stats.shape[0]), columns=sa_tuning_results_1.columns)\n",
    "        results['iter'] = i + 1\n",
    "        results['max_attempts'] = max_attempts\n",
    "        results['init_temp'] = end_stats['schedule_init_temp'].values\n",
    "        results['fitness'] = end_stats['Fitness'].values\n",
    "        results['time'] = end_stats['Time'].values\n",
    "        sa_tuning_results_1 = pd.concat([sa_tuning_results_1, results], axis=0)\n",
    "sa_tuning_results_1.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sa_tuning_results_1.groupby('max_attempts')['time'].mean().plot();\n",
    "sa_tuning_results_1.groupby('max_attempts')['fitness'].mean().plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sa_tuning_results_1.to_csv('./results/sa_tuning_4pks_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SIMULATED ANNEALING TUNING (init temp)\n",
    "max_iter = 10000\n",
    "max_attempts = 100\n",
    "sa_tuning_results_2 = pd.DataFrame(columns=['iter', 'max_attempts', 'init_temp', 'fitness', 'time'])\n",
    "for i in range(5):\n",
    "    for temp in [.1, .5, 1, 2, 5, 10, 50, 100, 1000]:\n",
    "        problem.reset()\n",
    "        sa_runner = mlrose.SARunner(\n",
    "            problem,\n",
    "            '',\n",
    "            seed=42*(i+1),\n",
    "            iteration_list=[max_iter],\n",
    "            temperature_list=[temp],\n",
    "            max_attempts=max_attempts,\n",
    "        )\n",
    "        stats, _ = sa_runner.run()\n",
    "        end_stats = stats.query('Iteration==@max_iter').reset_index(drop=True)\n",
    "        results = pd.DataFrame(index=range(end_stats.shape[0]), columns=sa_tuning_results_2.columns)\n",
    "        results['iter'] = i + 1\n",
    "        results['max_attempts'] = max_attempts\n",
    "        results['init_temp'] = end_stats['schedule_init_temp'].values\n",
    "        results['fitness'] = end_stats['Fitness'].values\n",
    "        results['time'] = end_stats['Time'].values\n",
    "        sa_tuning_results_2 = pd.concat([sa_tuning_results_2, results], axis=0)\n",
    "sa_tuning_results_2.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sa_tuning_results_2.groupby('init_temp')['time'].mean().plot();\n",
    "sa_tuning_results_2.groupby('init_temp')['fitness'].mean().plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sa_tuning_results_2.groupby('init_temp')['fitness'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sa_tuning_results_2.groupby('init_temp')['time'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sa_tuning_results_2.to_csv('./results/sa_tuning_4pks_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SIMULATED ANNEALING TUNING (decay)\n",
    "max_iter = 10000\n",
    "max_attempts = 100\n",
    "temp = .5\n",
    "sa_tuning_results_3 = pd.DataFrame(columns=['iter', 'max_attempts', 'init_temp', 'decay', 'fitness', 'time'])\n",
    "for i in range(5):\n",
    "    for decay in [.95, .99, .995, .999, .9995, .9999]:\n",
    "        problem.reset()\n",
    "        sa_runner = mlrose.SARunner(\n",
    "            problem,\n",
    "            '',\n",
    "            seed=42*(i+1),\n",
    "            iteration_list=[max_iter],\n",
    "            temperature_list=[mlrose.GeomDecay(temp, decay=decay)],\n",
    "            max_attempts=max_attempts,\n",
    "        )\n",
    "        stats, _ = sa_runner.run()\n",
    "        end_stats = stats.query('Iteration==@max_iter').reset_index(drop=True)\n",
    "        results = pd.DataFrame(index=range(end_stats.shape[0]), columns=sa_tuning_results_3.columns)\n",
    "        results['iter'] = i + 1\n",
    "        results['max_attempts'] = max_attempts\n",
    "        results['init_temp'] = end_stats['schedule_init_temp'].values\n",
    "        results['decay'] = decay\n",
    "        results['fitness'] = end_stats['Fitness'].values\n",
    "        results['time'] = end_stats['Time'].values\n",
    "        sa_tuning_results_3 = pd.concat([sa_tuning_results_3, results], axis=0)\n",
    "sa_tuning_results_3.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sa_tuning_results_3.groupby('decay')['time'].mean().plot();\n",
    "sa_tuning_results_3.groupby('decay')['fitness'].mean().plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sa_tuning_results_3.groupby('decay')['time'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sa_tuning_results_3.groupby('decay')['fitness'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sa_tuning_results_3.to_csv('./results/sa_tuning_4pks_3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GENETIC ALGORITHM TUNING (mutation rates)\n",
    "max_iter = 1000\n",
    "max_attempts = 200\n",
    "population_sizes = [200]\n",
    "cols = ['iter', 'max_attempts', 'pop_size', 'mutation_rate', 'fitness', 'time']\n",
    "ga_tuning_results_1 = pd.DataFrame(columns=cols)\n",
    "for i in range(5):\n",
    "    for mutation_rate in [.01, .1, .2, .5, 1]:\n",
    "        problem.reset()\n",
    "        ga_runner = mlrose.GARunner(\n",
    "            problem,\n",
    "            '',\n",
    "            seed=42*(i+1),\n",
    "            iteration_list=[max_iter],\n",
    "            population_sizes=population_sizes,\n",
    "            mutation_rates=[mutation_rate],\n",
    "            max_attempts=max_attempts\n",
    "        )\n",
    "        stats, _ = ga_runner.run()\n",
    "        end_stats = stats.query('Iteration==@max_iter').reset_index(drop=True)\n",
    "        results = pd.DataFrame(index=range(end_stats.shape[0]), columns=ga_tuning_results_1.columns)\n",
    "        results['iter'] = i + 1\n",
    "        results['max_attempts'] = max_attempts\n",
    "        results['pop_size'] = end_stats['Population Size'].values\n",
    "        results['mutation_rate'] = end_stats['Mutation Rate'].values\n",
    "        results['fitness'] = end_stats['Fitness'].values\n",
    "        results['time'] = end_stats['Time'].values\n",
    "        ga_tuning_results_1 = pd.concat([ga_tuning_results_1, results], axis=0)\n",
    "ga_tuning_results_1.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ga_tuning_results_1.groupby('mutation_rate')['time'].mean().plot();\n",
    "ga_tuning_results_1.groupby('mutation_rate')['fitness'].mean().plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ga_tuning_results_1.groupby('mutation_rate')['fitness'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ga_tuning_results_1.groupby('mutation_rate')['time'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ga_tuning_results_1.to_csv('./results/ga_tuning_4pks_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GENETIC ALGORITHM TUNING (max attempts)\n",
    "max_iter = 1000\n",
    "population_sizes = [200]\n",
    "mutation_rates = [.5]\n",
    "cols = ['iter', 'max_attempts', 'pop_size', 'mutation_rate', 'fitness', 'time']\n",
    "ga_tuning_results_2 = pd.DataFrame(columns=cols)\n",
    "for i in range(3):\n",
    "    for max_attempts in [1, 5, 10, 25, 50, 100]:\n",
    "        problem.reset()\n",
    "        ga_runner = mlrose.GARunner(\n",
    "            problem,\n",
    "            '',\n",
    "            seed=42*(i+1),\n",
    "            iteration_list=[max_iter],\n",
    "            population_sizes=population_sizes,\n",
    "            mutation_rates=mutation_rates,\n",
    "            max_attempts=max_attempts\n",
    "        )\n",
    "        stats, _ = ga_runner.run()\n",
    "        end_stats = stats.query('Iteration==@max_iter').reset_index(drop=True)\n",
    "        results = pd.DataFrame(index=range(end_stats.shape[0]), columns=ga_tuning_results_2.columns)\n",
    "        results['iter'] = i + 1\n",
    "        results['max_attempts'] = max_attempts\n",
    "        results['pop_size'] = end_stats['Population Size'].values\n",
    "        results['mutation_rate'] = end_stats['Mutation Rate'].values\n",
    "        results['fitness'] = end_stats['Fitness'].values\n",
    "        results['time'] = end_stats['Time'].values\n",
    "        ga_tuning_results_2 = pd.concat([ga_tuning_results_2, results], axis=0)\n",
    "ga_tuning_results_2.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ga_tuning_results_2.groupby('max_attempts')['time'].mean().plot();\n",
    "ga_tuning_results_2.groupby('max_attempts')['fitness'].mean().plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ga_tuning_results_2.to_csv('./results/ga_tuning_4pks_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ga_tuning_results_2.groupby('max_attempts')['fitness'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GENETIC ALGORITHM TUNING (pop size)\n",
    "max_iter = 1000\n",
    "max_attempts = 25\n",
    "mutation_rates = [.5]\n",
    "cols = ['iter', 'max_attempts', 'pop_size', 'mutation_rate', 'fitness', 'time']\n",
    "ga_tuning_results_3 = pd.DataFrame(columns=cols)\n",
    "for i in range(3):\n",
    "    for population_size in [25, 50, 100, 200, 500, 1000]:\n",
    "        problem.reset()\n",
    "        ga_runner = mlrose.GARunner(\n",
    "            problem,\n",
    "            '',\n",
    "            seed=42*(i+1),\n",
    "            iteration_list=[max_iter],\n",
    "            population_sizes=[population_size],\n",
    "            mutation_rates=mutation_rates,\n",
    "            max_attempts=max_attempts\n",
    "        )\n",
    "        stats, _ = ga_runner.run()\n",
    "        end_stats = stats.query('Iteration==@max_iter').reset_index(drop=True)\n",
    "        results = pd.DataFrame(index=range(end_stats.shape[0]), columns=ga_tuning_results_3.columns)\n",
    "        results['iter'] = i + 1\n",
    "        results['max_attempts'] = max_attempts\n",
    "        results['pop_size'] = end_stats['Population Size'].values\n",
    "        results['mutation_rate'] = end_stats['Mutation Rate'].values\n",
    "        results['fitness'] = end_stats['Fitness'].values\n",
    "        results['time'] = end_stats['Time'].values\n",
    "        ga_tuning_results_3 = pd.concat([ga_tuning_results_3, results], axis=0)\n",
    "ga_tuning_results_3.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ga_tuning_results_3.groupby('pop_size')['time'].mean().plot();\n",
    "ga_tuning_results_3.groupby('pop_size')['fitness'].mean().plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ga_tuning_results_3.groupby('pop_size')['fitness'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ga_tuning_results_3.groupby('pop_size')['time'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ga_tuning_results_3.to_csv('./results/ga_tuning_4pks_3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MIMIC TUNING (max attempts)\n",
    "max_iter = 1000\n",
    "population_sizes = [200]\n",
    "keep_pcts = [.2]\n",
    "cols = ['iter', 'max_attempts', 'pop_size', 'keep_pct', 'fitness', 'time']\n",
    "mimic_tuning_results_1 = pd.DataFrame(columns=cols)\n",
    "for i in range(3):\n",
    "    for max_attempts in [1, 2, 5, 10, 25, 50, 100]:\n",
    "        problem.reset()\n",
    "        mimic_runner = mlrose.MIMICRunner(\n",
    "            problem,\n",
    "            '',\n",
    "            seed=42*(i+1),\n",
    "            iteration_list=[max_iter],\n",
    "            population_sizes=population_sizes,\n",
    "            keep_percent_list=keep_pcts,\n",
    "            max_attempts=max_attempts,\n",
    "            use_fast_mimic=True\n",
    "        )\n",
    "        stats, _ = mimic_runner.run()\n",
    "        end_stats = stats.query('Iteration==@max_iter').reset_index(drop=True)\n",
    "        results = pd.DataFrame(index=range(end_stats.shape[0]), columns=mimic_tuning_results_1.columns)\n",
    "        results['iter'] = i + 1\n",
    "        results['max_attempts'] = max_attempts\n",
    "        results['pop_size'] = end_stats['Population Size'].values\n",
    "        results['keep_pct'] = end_stats['Keep Percent'].values\n",
    "        results['fitness'] = end_stats['Fitness'].values\n",
    "        results['time'] = end_stats['Time'].values\n",
    "        mimic_tuning_results_1 = pd.concat([mimic_tuning_results_1, results], axis=0)\n",
    "mimic_tuning_results_1.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mimic_tuning_results_1.groupby('max_attempts')['time'].mean().plot();\n",
    "mimic_tuning_results_1.groupby('max_attempts')['fitness'].mean().plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mimic_tuning_results_1.groupby('max_attempts')['fitness'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mimic_tuning_results_1.to_csv('./results/mimic_tuning_4pks_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MIMIC TUNING (pop size)\n",
    "max_iter = 1000\n",
    "keep_pcts = [.2]\n",
    "max_attempts = 25\n",
    "cols = ['iter', 'max_attempts', 'pop_size', 'keep_pct', 'fitness', 'time']\n",
    "mimic_tuning_results_2 = pd.DataFrame(columns=cols)\n",
    "for i in range(3):\n",
    "    for pop_size in [50, 100, 200, 500, 1000, 2000]:\n",
    "        population_sizes = [pop_size]\n",
    "        problem.reset()\n",
    "        mimic_runner = mlrose.MIMICRunner(\n",
    "            problem,\n",
    "            '',\n",
    "            seed=42*(i+1),\n",
    "            iteration_list=[max_iter],\n",
    "            population_sizes=population_sizes,\n",
    "            keep_percent_list=keep_pcts,\n",
    "            max_attempts=max_attempts,\n",
    "            use_fast_mimic=True\n",
    "        )\n",
    "        stats, _ = mimic_runner.run()\n",
    "        end_stats = stats.query('Iteration==@max_iter').reset_index(drop=True)\n",
    "        results = pd.DataFrame(index=range(end_stats.shape[0]), columns=mimic_tuning_results_2.columns)\n",
    "        results['iter'] = i + 1\n",
    "        results['max_attempts'] = max_attempts\n",
    "        results['pop_size'] = end_stats['Population Size'].values\n",
    "        results['keep_pct'] = end_stats['Keep Percent'].values\n",
    "        results['fitness'] = end_stats['Fitness'].values\n",
    "        results['time'] = end_stats['Time'].values\n",
    "        mimic_tuning_results_2 = pd.concat([mimic_tuning_results_2, results], axis=0)\n",
    "mimic_tuning_results_2.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mimic_tuning_results_2.groupby('pop_size')['time'].mean().plot();\n",
    "mimic_tuning_results_2.groupby('pop_size')['fitness'].mean().plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mimic_tuning_results_2.groupby('pop_size')['time'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mimic_tuning_results_2.groupby('pop_size')['fitness'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mimic_tuning_results_2.to_csv('./results/mimic_tuning_4pks_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MIMIC TUNING (keep pct)\n",
    "max_iter = 1000\n",
    "population_sizes = [1000]\n",
    "max_attempts = 25\n",
    "cols = ['iter', 'max_attempts', 'pop_size', 'keep_pct', 'fitness', 'time']\n",
    "mimic_tuning_results_3 = pd.DataFrame(columns=cols)\n",
    "for i in range(3):\n",
    "    for keep_pct in [.05, .1, .2, .3, .5]:\n",
    "        keep_pcts = [keep_pct]\n",
    "        problem.reset()\n",
    "        mimic_runner = mlrose.MIMICRunner(\n",
    "            problem,\n",
    "            '',\n",
    "            seed=42*(i+1),\n",
    "            iteration_list=[max_iter],\n",
    "            population_sizes=population_sizes,\n",
    "            keep_percent_list=keep_pcts,\n",
    "            max_attempts=max_attempts,\n",
    "            use_fast_mimic=True\n",
    "        )\n",
    "        stats, _ = mimic_runner.run()\n",
    "        end_stats = stats.query('Iteration==@max_iter').reset_index(drop=True)\n",
    "        results = pd.DataFrame(index=range(end_stats.shape[0]), columns=mimic_tuning_results_3.columns)\n",
    "        results['iter'] = i + 1\n",
    "        results['max_attempts'] = max_attempts\n",
    "        results['pop_size'] = end_stats['Population Size'].values\n",
    "        results['keep_pct'] = end_stats['Keep Percent'].values\n",
    "        results['fitness'] = end_stats['Fitness'].values\n",
    "        results['time'] = end_stats['Time'].values\n",
    "        mimic_tuning_results_3 = pd.concat([mimic_tuning_results_3, results], axis=0)\n",
    "mimic_tuning_results_3.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mimic_tuning_results_3.groupby('keep_pct')['time'].mean().plot();\n",
    "mimic_tuning_results_3.groupby('keep_pct')['fitness'].mean().plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mimic_tuning_results_3.groupby('keep_pct')['time'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mimic_tuning_results_3.groupby('keep_pct')['fitness'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mimic_tuning_results_3.to_csv('./results/mimic_tuning_4pks_3.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4 Peaks Final Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "problem_sizes = [64, 110, 160]\n",
    "prob_seed = 4200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RANDOM HILL CLIMBING\n",
    "max_iter = 1000\n",
    "step = 10\n",
    "iteration_list = np.arange(step, max_iter+1, step)\n",
    "max_attempts = 100\n",
    "restarts = 75\n",
    "cols = ['prob_size', 'iter', 'iteration', 'max_attempts', 'restarts', 'fitness', 'time', 'f_evals']\n",
    "hc_final_results = pd.DataFrame(columns=cols)\n",
    "for prob_size in problem_sizes:\n",
    "    for i in range(3):\n",
    "        fitness_fn = mlrose.FourPeaks(t_pct=.1)\n",
    "        basic_opt = mlrose.DiscreteOpt(prob_size, fitness_fn=fitness_fn)\n",
    "        crossover = mlrose.OnePointCrossOver(basic_opt)\n",
    "        mutator = mlrose.ChangeOneMutator(basic_opt)\n",
    "        np.random.seed(prob_seed)\n",
    "        problem = mlrose.DiscreteOpt(prob_size, fitness_fn=fitness_fn, crossover=crossover, mutator=mutator)\n",
    "        hc_runner = mlrose.RHCRunner(\n",
    "            problem,\n",
    "            '',\n",
    "            seed=420*(i+1),\n",
    "            iteration_list=iteration_list,\n",
    "            restart_list=[restarts],\n",
    "            max_attempts=max_attempts,\n",
    "            generate_curves=True\n",
    "        )\n",
    "        stats, _ = hc_runner.run()\n",
    "        n_rows = stats.drop_duplicates('Iteration').shape[0]\n",
    "        results = pd.DataFrame(index=range(n_rows), columns=hc_final_results.columns)\n",
    "        results['prob_size'] = prob_size\n",
    "        results['iter'] = i + 1\n",
    "        results['max_attempts'] = max_attempts\n",
    "        results['restarts'] = restarts\n",
    "        results['iteration'] = stats.drop_duplicates('Iteration')['Iteration'].values\n",
    "        results['fitness'] = stats.groupby('Iteration')['Fitness'].max().values\n",
    "        stats['time_per_iter'] = stats['Time'].diff().fillna(stats['Time'].min())\n",
    "        results['time'] = stats.groupby('Iteration')['time_per_iter'].mean().cumsum().values\n",
    "        stats['evals_per_iter'] = stats['FEvals'].diff().fillna(stats['FEvals'].min())\n",
    "        results['f_evals'] = stats.groupby('Iteration')['evals_per_iter'].mean().cumsum().values\n",
    "        hc_final_results = pd.concat([hc_final_results, results], axis=0)\n",
    "hc_final_results.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for prob_size in problem_sizes:\n",
    "    hc_final_results.query(\n",
    "        'prob_size==@prob_size'\n",
    "    ).drop_duplicates(['time']).groupby('iteration')['fitness'].mean().plot(\n",
    "        label=prob_size, legend=True\n",
    "    );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hc_final_results.to_csv('./results/hc_final_4pks.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SIMULATED ANNEALING\n",
    "max_iter = 40000\n",
    "step = 10\n",
    "iteration_list = np.arange(step, max_iter+1, step)\n",
    "max_attempts = 100\n",
    "decay = .995\n",
    "init_temp = .5\n",
    "cols = ['prob_size', 'iter', 'iteration', 'max_attempts', 'init_temp', 'decay', 'fitness', 'time', 'f_evals']\n",
    "sa_final_results = pd.DataFrame(columns=cols)\n",
    "for prob_size in problem_sizes:\n",
    "    for i in range(3):\n",
    "        fitness_fn = mlrose.FourPeaks(t_pct=.1)\n",
    "        basic_opt = mlrose.DiscreteOpt(prob_size, fitness_fn=fitness_fn)\n",
    "        crossover = mlrose.OnePointCrossOver(basic_opt)\n",
    "        mutator = mlrose.ChangeOneMutator(basic_opt)\n",
    "        np.random.seed(prob_seed)\n",
    "        problem = mlrose.DiscreteOpt(prob_size, fitness_fn=fitness_fn, crossover=crossover, mutator=mutator)\n",
    "        sa_runner = mlrose.SARunner(\n",
    "            problem,\n",
    "            '',\n",
    "            seed=420*(i+1),\n",
    "            iteration_list=iteration_list,\n",
    "            max_attempts=max_attempts,\n",
    "            temperature_list=[mlrose.GeomDecay(init_temp, decay=decay)],\n",
    "        )\n",
    "        stats, _ = sa_runner.run()\n",
    "        n_rows = stats.shape[0]\n",
    "        results = pd.DataFrame(index=range(n_rows), columns=sa_final_results.columns)\n",
    "        results['prob_size'] = prob_size\n",
    "        results['iter'] = i + 1\n",
    "        results['max_attempts'] = max_attempts\n",
    "        results['init_temp'] = init_temp\n",
    "        results['decay'] = decay\n",
    "        results['iteration'] = stats['Iteration'].values\n",
    "        results['fitness'] = stats['Fitness'].values\n",
    "        results['time'] = stats['Time'].values\n",
    "        results['f_evals'] = stats['FEvals'].values\n",
    "        sa_final_results = pd.concat([sa_final_results, results], axis=0)\n",
    "sa_final_results.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for prob_size in problem_sizes:\n",
    "    sa_final_results.query(\n",
    "        'prob_size==@prob_size'\n",
    "    ).drop_duplicates(['time']).groupby('iteration')['fitness'].mean().plot(\n",
    "        label=prob_size, legend=True\n",
    "    );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sa_final_results.to_csv('./results/sa_final_4pks.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GENETIC ALGORITHM\n",
    "max_iter = 1000\n",
    "step = 10\n",
    "iteration_list = np.arange(step, max_iter+1, step)\n",
    "max_attempts = 25\n",
    "pop_size = 500\n",
    "mutation_rate = .5\n",
    "cols = ['prob_size', 'iter', 'iteration', 'max_attempts', 'pop_size', 'mutation_rate', 'fitness', 'time', 'f_evals']\n",
    "ga_final_results = pd.DataFrame(columns=cols)\n",
    "for prob_size in problem_sizes:\n",
    "    for i in range(3):\n",
    "        fitness_fn = mlrose.FourPeaks(t_pct=.1)\n",
    "        basic_opt = mlrose.DiscreteOpt(prob_size, fitness_fn=fitness_fn)\n",
    "        crossover = mlrose.OnePointCrossOver(basic_opt)\n",
    "        mutator = mlrose.ChangeOneMutator(basic_opt)\n",
    "        np.random.seed(prob_seed)\n",
    "        problem = mlrose.DiscreteOpt(prob_size, fitness_fn=fitness_fn, crossover=crossover, mutator=mutator)\n",
    "        ga_runner = mlrose.GARunner(\n",
    "            problem,\n",
    "            '',\n",
    "            seed=420*(i+1),\n",
    "            iteration_list=iteration_list,\n",
    "            max_attempts=max_attempts,\n",
    "            population_sizes=[pop_size],\n",
    "            mutation_rates=[mutation_rate]\n",
    "        )\n",
    "        stats, _ = ga_runner.run()\n",
    "        n_rows = stats.shape[0]\n",
    "        results = pd.DataFrame(index=range(n_rows), columns=ga_final_results.columns)\n",
    "        results['prob_size'] = prob_size\n",
    "        results['iter'] = i + 1\n",
    "        results['max_attempts'] = max_attempts\n",
    "        results['pop_size'] = pop_size\n",
    "        results['mutation_rate'] = mutation_rate\n",
    "        results['iteration'] = stats['Iteration'].values\n",
    "        results['fitness'] = stats['Fitness'].values\n",
    "        results['time'] = stats['Time'].values\n",
    "        results['f_evals'] = stats['FEvals'].values\n",
    "        ga_final_results = pd.concat([ga_final_results, results], axis=0)\n",
    "ga_final_results.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for prob_size in problem_sizes:\n",
    "    ga_final_results.query(\n",
    "        'prob_size==@prob_size'\n",
    "    ).drop_duplicates(['time']).groupby('iteration')['fitness'].mean().plot(\n",
    "        label=prob_size, legend=True\n",
    "    );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ga_final_results.to_csv('./results/ga_final_4pks.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MIMIC\n",
    "max_iter = 1000\n",
    "step = 10\n",
    "iteration_list = np.arange(step, max_iter+1, step)\n",
    "max_attempts = 25\n",
    "pop_size = 1000\n",
    "keep_pct = .2\n",
    "cols = ['prob_size', 'iter', 'iteration', 'max_attempts', 'pop_size', 'keep_pct', 'fitness', 'time', 'f_evals']\n",
    "mimic_final_results = pd.DataFrame(columns=cols)\n",
    "for prob_size in problem_sizes:\n",
    "    for i in range(3):\n",
    "        fitness_fn = mlrose.FourPeaks(t_pct=.1)\n",
    "        basic_opt = mlrose.DiscreteOpt(prob_size, fitness_fn=fitness_fn)\n",
    "        crossover = mlrose.OnePointCrossOver(basic_opt)\n",
    "        mutator = mlrose.ChangeOneMutator(basic_opt)\n",
    "        np.random.seed(prob_seed)\n",
    "        problem = mlrose.DiscreteOpt(prob_size, fitness_fn=fitness_fn, crossover=crossover, mutator=mutator)\n",
    "        mimic_runner = mlrose.MIMICRunner(\n",
    "            problem,\n",
    "            '',\n",
    "            seed=420*(i+1),\n",
    "            iteration_list=iteration_list,\n",
    "            max_attempts=max_attempts,\n",
    "            population_sizes=[pop_size],\n",
    "            keep_percent_list=[keep_pct],\n",
    "            use_fast_mimic=True\n",
    "        )\n",
    "        stats, _ = mimic_runner.run()\n",
    "        n_rows = stats.shape[0]\n",
    "        results = pd.DataFrame(index=range(n_rows), columns=mimic_final_results.columns)\n",
    "        results['prob_size'] = prob_size\n",
    "        results['iter'] = i + 1\n",
    "        results['max_attempts'] = max_attempts\n",
    "        results['pop_size'] = pop_size\n",
    "        results['keep_pct'] = keep_pct\n",
    "        results['iteration'] = stats['Iteration'].values\n",
    "        results['fitness'] = stats['Fitness'].values\n",
    "        results['time'] = stats['Time'].values\n",
    "        results['f_evals'] = stats['FEvals'].values\n",
    "        mimic_final_results = pd.concat([mimic_final_results, results], axis=0)\n",
    "mimic_final_results.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for prob_size in problem_sizes:\n",
    "    mimic_final_results.query(\n",
    "        'prob_size==@prob_size'\n",
    "    ).drop_duplicates(['time']).groupby('iteration')['fitness'].mean().plot(\n",
    "        label=prob_size, legend=True\n",
    "    );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mimic_final_results.to_csv('./results/mimic_final_4pks.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Flip Flop Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "problem = mlrose.FlipFlopGenerator().generate(420, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HILL CLIMBING TUNING (restarts and max attempts)\n",
    "max_iter = 1000\n",
    "restarts = 100\n",
    "hc_tuning_results = pd.DataFrame(columns=['iter', 'max_attempts', 'restart', 'fitness', 'time'])\n",
    "for max_attempts in [1, 5, 10, 25, 50, 100]:\n",
    "    for i in range(5):\n",
    "        problem.reset()\n",
    "        hc_runner = mlrose.RHCRunner(\n",
    "            problem,\n",
    "            '',\n",
    "            seed=42*(i+1),\n",
    "            iteration_list=[max_iter],\n",
    "            restart_list=[restarts],\n",
    "            max_attempts=max_attempts,\n",
    "            generate_curves=True\n",
    "        )\n",
    "        stats, _ = hc_runner.run()\n",
    "        end_stats = stats.query('Iteration==@max_iter').reset_index(drop=True)\n",
    "        results = pd.DataFrame(index=range(end_stats.shape[0]), columns=hc_tuning_results.columns)\n",
    "        results['iter'] = i + 1\n",
    "        results['max_attempts'] = max_attempts\n",
    "        results['restart'] = end_stats['current_restart'].values\n",
    "        results['fitness'] = end_stats['Fitness'].cummax().values\n",
    "        results['time'] = end_stats['Time'].values\n",
    "        hc_tuning_results = pd.concat([hc_tuning_results, results], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hc_tuning_results.groupby(['max_attempts', 'restart'])['time'].mean().unstack().T.plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hc_tuning_results.groupby(['max_attempts', 'restart'])['fitness'].mean().unstack().T.plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hc_tuning_results.to_csv('./results/hc_tuning_ff.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SIMULATED ANNEALING TUNING (max attempts)\n",
    "max_iter = 10000\n",
    "sa_tuning_results_1 = pd.DataFrame(columns=['iter', 'max_attempts', 'init_temp', 'fitness', 'time'])\n",
    "for i in range(5):\n",
    "    for max_attempts in [10, 25, 50, 100, 200, 500]:\n",
    "        problem.reset()\n",
    "        sa_runner = mlrose.SARunner(\n",
    "            problem,\n",
    "            '',\n",
    "            seed=42*(i+1),\n",
    "            iteration_list=[max_iter],\n",
    "            temperature_list=[1],\n",
    "            max_attempts=max_attempts,\n",
    "        )\n",
    "        stats, _ = sa_runner.run()\n",
    "        end_stats = stats.query('Iteration==@max_iter').reset_index(drop=True)\n",
    "        results = pd.DataFrame(index=range(end_stats.shape[0]), columns=sa_tuning_results_1.columns)\n",
    "        results['iter'] = i + 1\n",
    "        results['max_attempts'] = max_attempts\n",
    "        results['init_temp'] = end_stats['schedule_init_temp'].values\n",
    "        results['fitness'] = end_stats['Fitness'].values\n",
    "        results['time'] = end_stats['Time'].values\n",
    "        sa_tuning_results_1 = pd.concat([sa_tuning_results_1, results], axis=0)\n",
    "sa_tuning_results_1.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sa_tuning_results_1.groupby('max_attempts')['time'].mean().plot();\n",
    "sa_tuning_results_1.groupby('max_attempts')['fitness'].mean().plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sa_tuning_results_1.to_csv('./results/sa_tuning_ff_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sa_tuning_results_1.groupby('max_attempts')['fitness'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sa_tuning_results_1.groupby('max_attempts')['time'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SIMULATED ANNEALING TUNING (init temp)\n",
    "max_iter = 10000\n",
    "max_attempts = 100\n",
    "sa_tuning_results_2 = pd.DataFrame(columns=['iter', 'max_attempts', 'init_temp', 'fitness', 'time'])\n",
    "for i in range(5):\n",
    "    for temp in [.1, .5, 1, 2, 5, 10, 50, 100]:\n",
    "        problem.reset()\n",
    "        sa_runner = mlrose.SARunner(\n",
    "            problem,\n",
    "            '',\n",
    "            seed=42*(i+1),\n",
    "            iteration_list=[max_iter],\n",
    "            temperature_list=[temp],\n",
    "            max_attempts=max_attempts,\n",
    "        )\n",
    "        stats, _ = sa_runner.run()\n",
    "        end_stats = stats.query('Iteration==@max_iter').reset_index(drop=True)\n",
    "        results = pd.DataFrame(index=range(end_stats.shape[0]), columns=sa_tuning_results_2.columns)\n",
    "        results['iter'] = i + 1\n",
    "        results['max_attempts'] = max_attempts\n",
    "        results['init_temp'] = end_stats['schedule_init_temp'].values\n",
    "        results['fitness'] = end_stats['Fitness'].values\n",
    "        results['time'] = end_stats['Time'].values\n",
    "        sa_tuning_results_2 = pd.concat([sa_tuning_results_2, results], axis=0)\n",
    "sa_tuning_results_2.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sa_tuning_results_2.groupby('init_temp')['time'].mean().plot();\n",
    "sa_tuning_results_2.groupby('init_temp')['fitness'].mean().plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sa_tuning_results_2.groupby('init_temp')['fitness'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sa_tuning_results_2.groupby('init_temp')['time'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sa_tuning_results_2.to_csv('./results/sa_tuning_ff_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SIMULATED ANNEALING TUNING (decay)\n",
    "max_iter = 10000\n",
    "max_attempts = 100\n",
    "temp = 10\n",
    "sa_tuning_results_3 = pd.DataFrame(columns=['iter', 'max_attempts', 'init_temp', 'decay', 'fitness', 'time'])\n",
    "for i in range(5):\n",
    "    for decay in [.95, .99, .995, .999, .9995, .9999]:\n",
    "        problem.reset()\n",
    "        sa_runner = mlrose.SARunner(\n",
    "            problem,\n",
    "            '',\n",
    "            seed=42*(i+1),\n",
    "            iteration_list=[max_iter],\n",
    "            temperature_list=[mlrose.GeomDecay(temp, decay=decay)],\n",
    "            max_attempts=max_attempts,\n",
    "        )\n",
    "        stats, _ = sa_runner.run()\n",
    "        end_stats = stats.query('Iteration==@max_iter').reset_index(drop=True)\n",
    "        results = pd.DataFrame(index=range(end_stats.shape[0]), columns=sa_tuning_results_3.columns)\n",
    "        results['iter'] = i + 1\n",
    "        results['max_attempts'] = max_attempts\n",
    "        results['init_temp'] = end_stats['schedule_init_temp'].values\n",
    "        results['decay'] = decay\n",
    "        results['fitness'] = end_stats['Fitness'].values\n",
    "        results['time'] = end_stats['Time'].values\n",
    "        sa_tuning_results_3 = pd.concat([sa_tuning_results_3, results], axis=0)\n",
    "sa_tuning_results_3.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sa_tuning_results_3.groupby('decay')['time'].mean().plot();\n",
    "sa_tuning_results_3.groupby('decay')['fitness'].mean().plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sa_tuning_results_3.groupby('decay')['time'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sa_tuning_results_3.groupby('decay')['fitness'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sa_tuning_results_3.to_csv('./results/sa_tuning_ff_3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GENETIC ALGORITHM TUNING (mutation rates)\n",
    "max_iter = 1000\n",
    "max_attempts = 200\n",
    "population_sizes = [200]\n",
    "cols = ['iter', 'max_attempts', 'pop_size', 'mutation_rate', 'fitness', 'time']\n",
    "ga_tuning_results_1 = pd.DataFrame(columns=cols)\n",
    "for i in range(1):\n",
    "    for mutation_rate in [.01, .1, .2, .5, 1]:\n",
    "        problem.reset()\n",
    "        ga_runner = mlrose.GARunner(\n",
    "            problem,\n",
    "            '',\n",
    "            seed=42*(i+1),\n",
    "            iteration_list=[max_iter],\n",
    "            population_sizes=population_sizes,\n",
    "            mutation_rates=[mutation_rate],\n",
    "            max_attempts=max_attempts\n",
    "        )\n",
    "        stats, _ = ga_runner.run()\n",
    "        end_stats = stats.query('Iteration==@max_iter').reset_index(drop=True)\n",
    "        results = pd.DataFrame(index=range(end_stats.shape[0]), columns=ga_tuning_results_1.columns)\n",
    "        results['iter'] = i + 1\n",
    "        results['max_attempts'] = max_attempts\n",
    "        results['pop_size'] = end_stats['Population Size'].values\n",
    "        results['mutation_rate'] = end_stats['Mutation Rate'].values\n",
    "        results['fitness'] = end_stats['Fitness'].values\n",
    "        results['time'] = end_stats['Time'].values\n",
    "        ga_tuning_results_1 = pd.concat([ga_tuning_results_1, results], axis=0)\n",
    "ga_tuning_results_1.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ga_tuning_results_1.groupby('mutation_rate')['time'].mean().plot();\n",
    "ga_tuning_results_1.groupby('mutation_rate')['fitness'].mean().plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ga_tuning_results_1.groupby('mutation_rate')['fitness'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ga_tuning_results_1.groupby('mutation_rate')['time'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ga_tuning_results_1.to_csv('./results/ga_tuning_ff_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GENETIC ALGORITHM TUNING (max attempts)\n",
    "max_iter = 1000\n",
    "population_sizes = [200]\n",
    "mutation_rates = [1]\n",
    "cols = ['iter', 'max_attempts', 'pop_size', 'mutation_rate', 'fitness', 'time']\n",
    "ga_tuning_results_2 = pd.DataFrame(columns=cols)\n",
    "for i in range(1):\n",
    "    for max_attempts in [1, 5, 10, 25, 50, 100, 200, 500]:\n",
    "        problem.reset()\n",
    "        ga_runner = mlrose.GARunner(\n",
    "            problem,\n",
    "            '',\n",
    "            seed=42*(i+1),\n",
    "            iteration_list=[max_iter],\n",
    "            population_sizes=population_sizes,\n",
    "            mutation_rates=mutation_rates,\n",
    "            max_attempts=max_attempts\n",
    "        )\n",
    "        stats, _ = ga_runner.run()\n",
    "        end_stats = stats.query('Iteration==@max_iter').reset_index(drop=True)\n",
    "        results = pd.DataFrame(index=range(end_stats.shape[0]), columns=ga_tuning_results_2.columns)\n",
    "        results['iter'] = i + 1\n",
    "        results['max_attempts'] = max_attempts\n",
    "        results['pop_size'] = end_stats['Population Size'].values\n",
    "        results['mutation_rate'] = end_stats['Mutation Rate'].values\n",
    "        results['fitness'] = end_stats['Fitness'].values\n",
    "        results['time'] = end_stats['Time'].values\n",
    "        ga_tuning_results_2 = pd.concat([ga_tuning_results_2, results], axis=0)\n",
    "ga_tuning_results_2.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ga_tuning_results_2.groupby('max_attempts')['time'].mean().plot();\n",
    "ga_tuning_results_2.groupby('max_attempts')['fitness'].mean().plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ga_tuning_results_2.groupby('max_attempts')['fitness'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ga_tuning_results_2.groupby('max_attempts')['time'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ga_tuning_results_2.to_csv('./results/ga_tuning_ff_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GENETIC ALGORITHM TUNING (pop size)\n",
    "max_iter = 1000\n",
    "max_attempts = 500\n",
    "mutation_rates = [1]\n",
    "cols = ['iter', 'max_attempts', 'pop_size', 'mutation_rate', 'fitness', 'time']\n",
    "ga_tuning_results_3 = pd.DataFrame(columns=cols)\n",
    "for i in range(1):\n",
    "    for population_size in [25, 50, 100, 200, 500, 1000]:\n",
    "        problem.reset()\n",
    "        ga_runner = mlrose.GARunner(\n",
    "            problem,\n",
    "            '',\n",
    "            seed=42*(i+1),\n",
    "            iteration_list=[max_iter],\n",
    "            population_sizes=[population_size],\n",
    "            mutation_rates=mutation_rates,\n",
    "            max_attempts=max_attempts\n",
    "        )\n",
    "        stats, _ = ga_runner.run()\n",
    "        end_stats = stats.query('Iteration==@max_iter').reset_index(drop=True)\n",
    "        results = pd.DataFrame(index=range(end_stats.shape[0]), columns=ga_tuning_results_3.columns)\n",
    "        results['iter'] = i + 1\n",
    "        results['max_attempts'] = max_attempts\n",
    "        results['pop_size'] = end_stats['Population Size'].values\n",
    "        results['mutation_rate'] = end_stats['Mutation Rate'].values\n",
    "        results['fitness'] = end_stats['Fitness'].values\n",
    "        results['time'] = end_stats['Time'].values\n",
    "        ga_tuning_results_3 = pd.concat([ga_tuning_results_3, results], axis=0)\n",
    "ga_tuning_results_3.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ga_tuning_results_3.groupby('pop_size')['time'].mean().plot();\n",
    "ga_tuning_results_3.groupby('pop_size')['fitness'].mean().plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ga_tuning_results_3.groupby('pop_size')['fitness'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ga_tuning_results_3.groupby('pop_size')['time'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ga_tuning_results_3.to_csv('./results/ga_tuning_ff_3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MIMIC TUNING (max attempts)\n",
    "max_iter = 1000\n",
    "population_sizes = [500]\n",
    "keep_pcts = [.2]\n",
    "cols = ['iter', 'max_attempts', 'pop_size', 'keep_pct', 'fitness', 'time']\n",
    "mimic_tuning_results_1 = pd.DataFrame(columns=cols)\n",
    "for i in range(1):\n",
    "    for max_attempts in [1, 2, 5, 10, 25, 50]:\n",
    "        problem.reset()\n",
    "        mimic_runner = mlrose.MIMICRunner(\n",
    "            problem,\n",
    "            '',\n",
    "            seed=42*(i+1),\n",
    "            iteration_list=[max_iter],\n",
    "            population_sizes=population_sizes,\n",
    "            keep_percent_list=keep_pcts,\n",
    "            max_attempts=max_attempts,\n",
    "            use_fast_mimic=True\n",
    "        )\n",
    "        stats, _ = mimic_runner.run()\n",
    "        end_stats = stats.query('Iteration==@max_iter').reset_index(drop=True)\n",
    "        results = pd.DataFrame(index=range(end_stats.shape[0]), columns=mimic_tuning_results_1.columns)\n",
    "        results['iter'] = i + 1\n",
    "        results['max_attempts'] = max_attempts\n",
    "        results['pop_size'] = end_stats['Population Size'].values\n",
    "        results['keep_pct'] = end_stats['Keep Percent'].values\n",
    "        results['fitness'] = end_stats['Fitness'].values\n",
    "        results['time'] = end_stats['Time'].values\n",
    "        mimic_tuning_results_1 = pd.concat([mimic_tuning_results_1, results], axis=0)\n",
    "mimic_tuning_results_1.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mimic_tuning_results_1.groupby('max_attempts')['time'].mean().plot();\n",
    "mimic_tuning_results_1.groupby('max_attempts')['fitness'].mean().plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mimic_tuning_results_1.groupby('max_attempts')['fitness'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mimic_tuning_results_1.groupby('max_attempts')['time'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mimic_tuning_results_1.to_csv('./results/mimic_tuning_ff_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MIMIC TUNING (pop size)\n",
    "max_iter = 1000\n",
    "keep_pcts = [.2]\n",
    "max_attempts = 5\n",
    "cols = ['iter', 'max_attempts', 'pop_size', 'keep_pct', 'fitness', 'time']\n",
    "mimic_tuning_results_2 = pd.DataFrame(columns=cols)\n",
    "for i in range(1):\n",
    "    for pop_size in [50, 100, 200, 500, 1000, 2000, 5000]:\n",
    "        population_sizes = [pop_size]\n",
    "        problem.reset()\n",
    "        mimic_runner = mlrose.MIMICRunner(\n",
    "            problem,\n",
    "            '',\n",
    "            seed=42*(i+1),\n",
    "            iteration_list=[max_iter],\n",
    "            population_sizes=population_sizes,\n",
    "            keep_percent_list=keep_pcts,\n",
    "            max_attempts=max_attempts,\n",
    "            use_fast_mimic=True\n",
    "        )\n",
    "        stats, _ = mimic_runner.run()\n",
    "        end_stats = stats.query('Iteration==@max_iter').reset_index(drop=True)\n",
    "        results = pd.DataFrame(index=range(end_stats.shape[0]), columns=mimic_tuning_results_2.columns)\n",
    "        results['iter'] = i + 1\n",
    "        results['max_attempts'] = max_attempts\n",
    "        results['pop_size'] = end_stats['Population Size'].values\n",
    "        results['keep_pct'] = end_stats['Keep Percent'].values\n",
    "        results['fitness'] = end_stats['Fitness'].values\n",
    "        results['time'] = end_stats['Time'].values\n",
    "        mimic_tuning_results_2 = pd.concat([mimic_tuning_results_2, results], axis=0)\n",
    "mimic_tuning_results_2.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mimic_tuning_results_2.groupby('pop_size')['time'].mean().plot();\n",
    "mimic_tuning_results_2.groupby('pop_size')['fitness'].mean().plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mimic_tuning_results_2.groupby('pop_size')['time'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mimic_tuning_results_2.groupby('pop_size')['fitness'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mimic_tuning_results_2.to_csv('./results/mimic_tuning_ff_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MIMIC TUNING (keep pct)\n",
    "max_iter = 1000\n",
    "population_sizes = [5000]\n",
    "max_attempts = 5\n",
    "cols = ['iter', 'max_attempts', 'pop_size', 'keep_pct', 'fitness', 'time']\n",
    "mimic_tuning_results_3 = pd.DataFrame(columns=cols)\n",
    "for i in range(1):\n",
    "    for keep_pct in [.05, .1, .2, .3, .5]:\n",
    "        keep_pcts = [keep_pct]\n",
    "        problem.reset()\n",
    "        mimic_runner = mlrose.MIMICRunner(\n",
    "            problem,\n",
    "            '',\n",
    "            seed=42*(i+1),\n",
    "            iteration_list=[max_iter],\n",
    "            population_sizes=population_sizes,\n",
    "            keep_percent_list=keep_pcts,\n",
    "            max_attempts=max_attempts,\n",
    "            use_fast_mimic=True\n",
    "        )\n",
    "        stats, _ = mimic_runner.run()\n",
    "        end_stats = stats.query('Iteration==@max_iter').reset_index(drop=True)\n",
    "        results = pd.DataFrame(index=range(end_stats.shape[0]), columns=mimic_tuning_results_3.columns)\n",
    "        results['iter'] = i + 1\n",
    "        results['max_attempts'] = max_attempts\n",
    "        results['pop_size'] = end_stats['Population Size'].values\n",
    "        results['keep_pct'] = end_stats['Keep Percent'].values\n",
    "        results['fitness'] = end_stats['Fitness'].values\n",
    "        results['time'] = end_stats['Time'].values\n",
    "        mimic_tuning_results_3 = pd.concat([mimic_tuning_results_3, results], axis=0)\n",
    "mimic_tuning_results_3.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mimic_tuning_results_3.groupby('keep_pct')['time'].mean().plot();\n",
    "mimic_tuning_results_3.groupby('keep_pct')['fitness'].mean().plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mimic_tuning_results_3.groupby('keep_pct')['time'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mimic_tuning_results_3.groupby('keep_pct')['fitness'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mimic_tuning_results_3.to_csv('./results/mimic_tuning_ff_3.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Flip Flop Final Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "problem_sizes = [100, 200, 300]\n",
    "prob_seed = 4200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RANDOM HILL CLIMBING\n",
    "max_iter = 1000\n",
    "step = 10\n",
    "iteration_list = np.arange(step, max_iter+1, step)\n",
    "max_attempts = 100\n",
    "restarts = 100\n",
    "cols = ['prob_size', 'iter', 'iteration', 'max_attempts', 'restarts', 'fitness', 'time', 'f_evals']\n",
    "hc_final_results = pd.DataFrame(columns=cols)\n",
    "for prob_size in problem_sizes:\n",
    "    for i in range(3):\n",
    "        problem = mlrose.FlipFlopGenerator().generate(prob_seed, size=prob_size)\n",
    "        hc_runner = mlrose.RHCRunner(\n",
    "            problem,\n",
    "            '',\n",
    "            seed=420*(i+1),\n",
    "            iteration_list=iteration_list,\n",
    "            restart_list=[restarts],\n",
    "            max_attempts=max_attempts,\n",
    "            generate_curves=True\n",
    "        )\n",
    "        stats, _ = hc_runner.run()\n",
    "        n_rows = stats.drop_duplicates('Iteration').shape[0]\n",
    "        results = pd.DataFrame(index=range(n_rows), columns=hc_final_results.columns)\n",
    "        results['prob_size'] = prob_size\n",
    "        results['iter'] = i + 1\n",
    "        results['max_attempts'] = max_attempts\n",
    "        results['restarts'] = restarts\n",
    "        results['iteration'] = stats.drop_duplicates('Iteration')['Iteration'].values\n",
    "        results['fitness'] = stats.groupby('Iteration')['Fitness'].max().values\n",
    "        stats['time_per_iter'] = stats['Time'].diff().fillna(stats['Time'].min())\n",
    "        results['time'] = stats.groupby('Iteration')['time_per_iter'].mean().cumsum().values\n",
    "        stats['evals_per_iter'] = stats['FEvals'].diff().fillna(stats['FEvals'].min())\n",
    "        results['f_evals'] = stats.groupby('Iteration')['evals_per_iter'].mean().cumsum().values\n",
    "        hc_final_results = pd.concat([hc_final_results, results], axis=0)\n",
    "hc_final_results.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for prob_size in problem_sizes:\n",
    "    hc_final_results.query(\n",
    "        'prob_size==@prob_size'\n",
    "    ).drop_duplicates(['time']).groupby('iteration')['fitness'].mean().plot(\n",
    "        label=prob_size, legend=True\n",
    "    );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hc_final_results.to_csv('./results/hc_final_ff.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SIMULATED ANNEALING\n",
    "max_iter = 10000\n",
    "step = 10\n",
    "iteration_list = np.arange(step, max_iter+1, step)\n",
    "max_attempts = 100\n",
    "decay = .95\n",
    "init_temp = 10\n",
    "cols = ['prob_size', 'iter', 'iteration', 'max_attempts', 'init_temp', 'decay', 'fitness', 'time', 'f_evals']\n",
    "sa_final_results = pd.DataFrame(columns=cols)\n",
    "for prob_size in problem_sizes:\n",
    "    for i in range(3):\n",
    "        problem = mlrose.FlipFlopGenerator().generate(prob_seed, size=prob_size)\n",
    "        sa_runner = mlrose.SARunner(\n",
    "            problem,\n",
    "            '',\n",
    "            seed=420*(i+1),\n",
    "            iteration_list=iteration_list,\n",
    "            max_attempts=max_attempts,\n",
    "            temperature_list=[mlrose.GeomDecay(init_temp, decay=decay)],\n",
    "        )\n",
    "        stats, _ = sa_runner.run()\n",
    "        n_rows = stats.shape[0]\n",
    "        results = pd.DataFrame(index=range(n_rows), columns=sa_final_results.columns)\n",
    "        results['prob_size'] = prob_size\n",
    "        results['iter'] = i + 1\n",
    "        results['max_attempts'] = max_attempts\n",
    "        results['init_temp'] = init_temp\n",
    "        results['decay'] = decay\n",
    "        results['iteration'] = stats['Iteration'].values\n",
    "        results['fitness'] = stats['Fitness'].values\n",
    "        results['time'] = stats['Time'].values\n",
    "        results['f_evals'] = stats['FEvals'].values\n",
    "        sa_final_results = pd.concat([sa_final_results, results], axis=0)\n",
    "sa_final_results.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for prob_size in problem_sizes:\n",
    "    sa_final_results.query(\n",
    "        'prob_size==@prob_size'\n",
    "    ).drop_duplicates(['time']).groupby('iteration')['fitness'].mean().plot(\n",
    "        label=prob_size, legend=True\n",
    "    );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sa_final_results.to_csv('./results/sa_final_ff.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GENETIC ALGORITHM\n",
    "max_iter = 1000\n",
    "step = 10\n",
    "iteration_list = np.arange(step, max_iter+1, step)\n",
    "max_attempts = 500\n",
    "pop_size = 1000\n",
    "mutation_rate = 1\n",
    "cols = ['prob_size', 'iter', 'iteration', 'max_attempts', 'pop_size', 'mutation_rate', 'fitness', 'time', 'f_evals']\n",
    "ga_final_results = pd.DataFrame(columns=cols)\n",
    "for prob_size in problem_sizes:\n",
    "    for i in range(3):\n",
    "        problem = mlrose.FlipFlopGenerator().generate(prob_seed, size=prob_size)\n",
    "        ga_runner = mlrose.GARunner(\n",
    "            problem,\n",
    "            '',\n",
    "            seed=420*(i+1),\n",
    "            iteration_list=iteration_list,\n",
    "            max_attempts=max_attempts,\n",
    "            population_sizes=[pop_size],\n",
    "            mutation_rates=[mutation_rate]\n",
    "        )\n",
    "        stats, _ = ga_runner.run()\n",
    "        n_rows = stats.shape[0]\n",
    "        results = pd.DataFrame(index=range(n_rows), columns=ga_final_results.columns)\n",
    "        results['prob_size'] = prob_size\n",
    "        results['iter'] = i + 1\n",
    "        results['max_attempts'] = max_attempts\n",
    "        results['pop_size'] = pop_size\n",
    "        results['mutation_rate'] = mutation_rate\n",
    "        results['iteration'] = stats['Iteration'].values\n",
    "        results['fitness'] = stats['Fitness'].values\n",
    "        results['time'] = stats['Time'].values\n",
    "        results['f_evals'] = stats['FEvals'].values\n",
    "        ga_final_results = pd.concat([ga_final_results, results], axis=0)\n",
    "ga_final_results.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for prob_size in problem_sizes:\n",
    "    ga_final_results.query(\n",
    "        'prob_size==@prob_size'\n",
    "    ).drop_duplicates(['time']).groupby('iteration')['fitness'].mean().plot(\n",
    "        label=prob_size, legend=True\n",
    "    );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ga_final_results.to_csv('./results/ga_final_ff.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MIMIC\n",
    "max_iter = 1000\n",
    "step = 10\n",
    "iteration_list = np.arange(step, max_iter+1, step)\n",
    "max_attempts = 5\n",
    "pop_size = 5000\n",
    "keep_pct = .1\n",
    "cols = ['prob_size', 'iter', 'iteration', 'max_attempts', 'pop_size', 'keep_pct', 'fitness', 'time', 'f_evals']\n",
    "mimic_final_results = pd.DataFrame(columns=cols)\n",
    "for prob_size in problem_sizes:\n",
    "    for i in range(3):\n",
    "        problem = mlrose.FlipFlopGenerator().generate(prob_seed, size=prob_size)\n",
    "        mimic_runner = mlrose.MIMICRunner(\n",
    "            problem,\n",
    "            '',\n",
    "            seed=420*(i+1),\n",
    "            iteration_list=iteration_list,\n",
    "            max_attempts=max_attempts,\n",
    "            population_sizes=[pop_size],\n",
    "            keep_percent_list=[keep_pct],\n",
    "            use_fast_mimic=True\n",
    "        )\n",
    "        stats, _ = mimic_runner.run()\n",
    "        n_rows = stats.shape[0]\n",
    "        results = pd.DataFrame(index=range(n_rows), columns=mimic_final_results.columns)\n",
    "        results['prob_size'] = prob_size\n",
    "        results['iter'] = i + 1\n",
    "        results['max_attempts'] = max_attempts\n",
    "        results['pop_size'] = pop_size\n",
    "        results['keep_pct'] = keep_pct\n",
    "        results['iteration'] = stats['Iteration'].values\n",
    "        results['fitness'] = stats['Fitness'].values\n",
    "        results['time'] = stats['Time'].values\n",
    "        results['f_evals'] = stats['FEvals'].values\n",
    "        mimic_final_results = pd.concat([mimic_final_results, results], axis=0)\n",
    "mimic_final_results.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for prob_size in problem_sizes:\n",
    "    mimic_final_results.query(\n",
    "        'prob_size==@prob_size'\n",
    "    ).drop_duplicates(['time']).groupby('iteration')['fitness'].mean().plot(\n",
    "        label=prob_size, legend=True\n",
    "    );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mimic_final_results.to_csv('./results/mimic_final_ff.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
